{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#the-python-framework-for-ai-data-artisans","title":"The Python Framework for AI &amp; Data Artisans","text":"<p>Arkalos is an easy-to-use framework for data analysis, data science, building data apps, warehouses, AI agents, robots, ML, training LLMs with elegant syntax. It just works.</p>"},{"location":"#why-arkalos-beginner-and-micro-business-friendly","title":"Why Arkalos? Beginner- and Micro Business-Friendly","text":"<p>Arkalos makes it easy to get started, whether you're a beginner non-coder, scientist, or AI engineer.</p> <p>And small businesses can now leverage the power of data warehouses and AI on a budget and at speed.</p> <p>No more struggling with:</p> <ul> <li>Setting up your environment</li> <li>Spending hours searching for basic solutions</li> <li>Following instructions that just don't work</li> <li>Manually installing and managing packages</li> <li>Writing too much code for basic tasks</li> <li>Resolving import issues and errors</li> <li>Figuring out how to structure custom code and modules</li> <li>Growing from Jupyter Notebooks to full AI apps and pipelines</li> <li>Presenting your analysis and reports, or creating modern dashboards</li> <li>Connecting data sources and building data warehouses</li> <li>Training AI models and running LLMs locally</li> <li>Collaborating with teams or sharing code across devices</li> </ul> <p>The name Arkalos combines \"Arc\" and the Greek word \"Kalos,\" meaning \"a beautiful journey through the data.\"</p>"},{"location":"#modern-frontend-ui-and-interactive-dashboard","title":"Modern Frontend UI and Interactive Dashboard","text":"<p>Arkalos is a pre-configured fullstack FastAPI and React based framework. Ready to analyze data or write business applications.</p> <p>Simply return Altair and Polars DataFrame charts, like you do in a Jupyter Notebook, from the Python FastAPI endpoint.</p> <p>And frontend React will render a responsive and interactive chart automatically:</p> <p></p>"},{"location":"#ai-chat","title":"AI Chat","text":""},{"location":"#jsonl-logs","title":"JSONL Logs","text":"<p>Powerful logging system in JSONL format with a UI:</p> <p></p>"},{"location":"#deployment-ready","title":"Deployment-Ready","text":"<p>Arkalos comes with the pre-configured PM2, Nginx and GitHub Action scripts.</p> <p>Simply deploy your Python projects with <code>git push</code>.</p>"},{"location":"#beautiful-syntax-and-documentation","title":"Beautiful Syntax and Documentation","text":"<p>Arkalos offers:</p> <ul> <li>Beautiful Documentation: Clear, concise, and easy-to-follow guides, even if you are learning coding, Python or data science.</li> <li>Elegant Syntax: Simple code that's easy to write and read.</li> <li>Reliable Performance: Works out of the box with minimal setup.</li> </ul> <pre><code>uv init\nuv add arkalos\nuv run arkalos init\n\ncd frontend\nnpm install\nnpm run build\ncd ..\n\nuv run arkalos serve\n\n# That's it. Your workspace is ready to write code. It just works!\n</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> <p>\ud83d\ude80 Modern Python Workflow: Built with modern Python practices, libraries, and a package manager. Perfect for non-coders and AI engineers.</p> </li> <li> <p>\ud83d\udee0\ufe0f Hassle-Free Setup: No more struggling with environment setups, package installs, or import errors.</p> </li> <li> <p>\ud83e\udd1d Easy Collaboration &amp; Folder Structure: Share code across devices or with your team. Built-in workspace folder and file structure. Know where to put each file.</p> </li> <li> <p>\ud83d\udcd3 Jupyter Notebook Friendly: Start with a simple notebook and easily transition to scripts, full apps, or microservices.</p> </li> <li> <p>\ud83d\udd78\ufe0f Browser Automation &amp; Structured Web Crawling &amp; Scraping: Control a real browser to bypass auth and captchas, crawl dynamic websites, and extract structured data using simple annotations with CSS selectors, attributes, slices, and regex \u2014 no manual parsing needed.</p> </li> <li> <p>\ud83d\udcca Built-in Data Extractors &amp; Warehouse: Connect to Notion, Airtable, Google Drive, and more. Uses SQLite for a local, lightweight data warehouse.</p> </li> <li> <p>\ud83e\udd16 AI, LLM &amp; RAG Ready. Talk to Your Own Data: Train AI models, run LLMs, and build AI and RAG pipelines locally. Fully open-source and compliant. Built-in AI agent helps you to talk to your own data in natural language.</p> </li> <li> <p>\ud83d\udc1e Debugging and Logging Made Easy: Built-in utilities and Python extensions like <code>var_dump()</code> for quick variable inspection, <code>dd()</code> to halt code execution, and pre-configured logging for notices and errors.</p> </li> <li> <p>\ud83e\udde9 Extensible Architecture: Easily extend Arkalos components and inject your own dependencies with a modern, modular software design.</p> </li> <li> <p>\ud83d\udd17 Seamless Microservices: Deploy your own data or AI microservice like ChatGPT without the need to use external APIs to integrate with your existing platforms effortlessly.</p> </li> <li> <p>\ud83d\udd12 Data Privacy &amp; Compliance First: Run everything locally with full control. No need to send sensitive data to third parties. Fully open-source under the MIT license, and perfect for organizations needing data governance.</p> </li> </ul>"},{"location":"#truly-open-source-local-and-compliant","title":"Truly Open-Source, Local, and Compliant","text":"<p>Arkalos helps individuals and businesses analyze data securely, with everything running locally and fully compliant with regulations.</p>"},{"location":"#clusteranalyzer-datatransformer-and-altair-dendrogram-and-other-charts","title":"ClusterAnalyzer, DataTransformer and Altair Dendrogram and Other Charts","text":"<pre><code>dtf = (DataTransformer(df)\n    .renameColsSnakeCase()\n    .dropRowsByID(9432)\n    .dropCols(['id', 'dt_customer'])\n    .dropRowsDuplicate()\n    .dropRowsNullsAndNaNs()\n    .dropColsSameValueNoVariance()\n    .splitColsOneHotEncode(['education', 'marital_status'])\n)\n\ncln_df = dtf.get()  # Get cleaned Polars DataFrame\n\nprint(f'Dataset shape: {cln_df.shape}')\ncln_df.head()\n</code></pre> <pre><code>n_clusters = ca.findNClustersViaDendrogram()\nprint(f'Optimal clusters (dendrogram): {n_clusters}')\n\nca.createDendrogram()\n</code></pre>"},{"location":"#database-data-warehouse-migrations","title":"Database &amp; Data Warehouse Migrations","text":"<pre><code>class Migration(DatabaseMigration):\n\n    def up(self):\n\n        with DB().createTable('users') as table:\n            table.col('id').id()\n            table.col('name').string(64).notNull()\n            table.col('email').string().notNull()\n            table.col('is_admin').boolean().notNull().default('FALSE')\n            table.col('created_at').datetime().notNull().defaultNow()\n            table.col('updated_at').datetime().notNull().defaultNow()\n            table.indexUnique('email')\n\n\n\n    def down(self):\n        DB().dropTable('users')\n</code></pre>"},{"location":"#free-built-in-data-warehouse-and-integrations","title":"Free Built-In Data Warehouse and Integrations","text":"<p>Data warehouses are centralized repositories that connect multiple data sources to enable AI and analytics.</p> <p>Not every case needs complex and expensive tools like Snowflake or BigQuery. With Arkalos, you get a simple, local data warehouse right out of the box!</p> <p>Arkalos connects seamlessly to popular tools like Notion, Airtable, Google Drive, and HubSpot.</p> <p>Automatically detects and generates the schema.</p> <p>And syncs data into your own data warehouse.</p> config/data_sources.py<pre><code>    'airtable': {\n        'enabled': True,\n        'api_key': env('AIRTABLE_API_KEY'),\n        'base_id': env('AIRTABLE_BASE_ID'),\n        'tables': env('AIRTABLE_TABLES'),\n    }\n</code></pre> <p>SQLite is used as the default local data warehouse.</p> .env<pre><code>DWH_ENGINE=SQLite\nDWH_SCHEMA_PATH=data/dwh/schema.sql\nDWH_SQLITE_PATH=data/dwh/dwh.db\n</code></pre> <pre><code>uv run arkalos dwh sync\n</code></pre> scripts/etl/my_script.py<pre><code>from arkalos.data.extractors.airtable_extractor import AirtableExtractor\n# or for Notion\n# from arkalos.data.extractors.notion_extractor import NotionExtractor\nfrom arkalos.workflows.etl_workflow import ETLWorkflow\n\nwf = ETLWorkflow(AirtableExtractor)\nwf.run(drop_tables=True)\n</code></pre> <p>And that's it! Your data is imported automatically, ready for analysis or AI pipelines, and even accessible offline.</p>"},{"location":"#built-in-http-api-server-launch-a-python-data-or-ai-microservice","title":"Built-in HTTP API Server - Launch a Python Data or AI Microservice","text":"<p>Python is the world's fastest-growing programming language thanks to its rich ecosystem of data, AI, and scientific libraries.</p> <p>Arkalos lets freelancers, consultants, startups, businesses, and even governments add powerful data and AI capabilities to their products and platforms. Simply launch Arkalos as a microservice and integrate it seamlessly into your architecture.</p> <pre><code>uv run arkalos serve\n</code></pre>"},{"location":"#build-custom-ai-agents-without-abstraction","title":"Build Custom AI Agents Without Abstraction","text":"app/ai/actions/what_is_my_ip_action.py<pre><code>import socket\nfrom arkalos.ai import AIAction\n\nclass WhatIsMyIpAction(AIAction):\n\n    NAME = 'what_is_my_ip'\n    DESCRIPTION = 'Determine the user IP'\n\n    def run(self, message):\n        hostname = socket.gethostname()\n        ip = socket.gethostbyname(hostname)\n        return ip\n</code></pre> app/ai/actions/calc_action.py<pre><code>from arkalos.ai import AIAction\n\nclass CalcAction(AIAction):\n\n    NAME = 'calc'\n    DESCRIPTION = 'Calculate mathematical expressions and provide a single value'\n\n    def run(self, message):\n        prompt = f\"\"\"\n            ### Instructions:\n            You are a calculator. Calculate mathematical expression and provide an answer\n\n            ### Input:\n            Generate a proper mathematical formula based on this question `{message}`.\n\n            And calculate the final answer to this formula.\n\n            ### Response:\n            Respond as a single mathematical value to the expression\n        \"\"\"\n        return self.generateTextResponse(prompt)\n</code></pre>"},{"location":"#multi-task-agent-determine-which-action-to-take","title":"Multi-Task Agent - Determine Which Action to Take","text":"app/ai/agents/multi_agent.py<pre><code>from arkalos.ai import AIAgent, TextToSQLAction\n\nfrom app.ai.actions import WhatIsMyIpAction, CalcAction\n\n\n\nclass MultiAgent(AIAgent):\n\n    NAME = 'MultiAgent'\n\n    DESCRIPTION = 'An Agent that understands the intent, determines which task to perform and runs it.'\n\n    GREETING = 'Hi, I am a MultiAgent. I can tell your IP address, do basic math calculations or transform text to SQL.'\n\n    ACTIONS = [\n        WhatIsMyIpAction, \n        CalcAction, \n        TextToSQLAction\n    ]\n\n    def processMessage(self, message):\n        response = f\"Determining the intent and which task to run...\\n\"\n        which_action = self.whichAction(message)\n        response += f\"Based on your question, I determined this task: {which_action}\\n\"\n        response += f\"Running this task...\\n\"\n        output = self.runAction(which_action, message)\n        response += f\"Task output: {output}\\n\"\n        return response\n</code></pre>"},{"location":"#test-your-models-and-agents-locally","title":"Test Your Models and Agents Locally","text":"scripts/ai/agent.py<pre><code>from app.ai.agents import MultiAgent\n\nagent = MultiAgent()\nagent.runConsole()\n</code></pre> <pre><code>uv run scripts/ai/agent.py\n</code></pre>"},{"location":"#web-browser-automation-crawling-and-scraping","title":"Web Browser Automation, Crawling and Scraping","text":"notebooks/browser.ipynb<pre><code>from arkalos.browser import WebBrowser, WebBrowserTab\n\nbrowser = WebBrowser(WebBrowser.TYPE.REMOTE_CDP)\n\nasync def search_google(tab: WebBrowserTab):\n    await tab.goto('https://www.google.com')\n    search_input = tab.get_by_role('combobox', name='Search')\n    await search_input.click()\n    await search_input.fill('cats')\n    await search_input.press('Enter')\n    images_tab = tab.get_by_role('link', name='Images', exact=True)\n    await images_tab.click()\n\nawait browser.run(search_google)\n</code></pre> app/data/extractors/my_website_web_extractor.py<pre><code>from arkalos.data.extractors import WebExtractor, WebDetails, _\nfrom dataclasses import dataclass\nimport polars as pl\n\n@dataclass\nclass ArticleDetails(WebDetails):\n    CONTAINER = 'article[data-id]'\n\n    id: _[str, None, 'data-id']           # Attribute from container\n    url: _[str, 'a', 'href']              # Link\n    title: _[str, 'a']                    # Text from &lt;a&gt;\n    description: _[str, '[data-item=\"description\"]']\n    tags: _[list[str], '[data-item=\"tag\"]']\n    rating: _[int, '.rating', 1]          # Second child (after image)\n\nclass MyWebsiteWebExtractor(WebExtractor):\n    BASE_URL = 'https://mywebsite.com'\n    PAGE_CONTENT_SELECTOR = 'main'\n    SCROLL = True\n    DETAILS = ArticleDetails\n\n    async def crawlTechArticles(self):\n        return await self.crawlSpecificDetails(['/category/tech'])\n</code></pre> notebooks/my_web_crawler.ipynb<pre><code>from app.data.extractors.my_website_web_extractor import MyWebsiteWebExtractor\n\nmywebsite = MyWebsiteWebExtractor()\ndata = await mywebsite.crawlTechArticles()\n\ndf = pl.DataFrame(data)\ndf\n</code></pre>"},{"location":"#powerful-google-extractor","title":"Powerful Google Extractor","text":""},{"location":"#search-and-list-google-drive-files-spreadsheets-and-forms","title":"Search and List Google Drive Files, Spreadsheets and Forms","text":"<pre><code>import polars as pl\n\nfrom arkalos.utils import MimeType\nfrom arkalos.data.extractors import GoogleExtractor\n\ngoogle = GoogleExtractor()\n\nfolder_id = 'folder_id'\n\n# List files and their metadata in a Google Drive folder\nfiles = google.drive.listFiles(folder_id)\n\n# Search for files with regex and by type\nfiles = google.drive.listFiles(folder_id, name_pattern='report', file_types=[MimeType.DOC_PDF])\n\nprint(pl.DataFrame(files))\n</code></pre>"},{"location":"#list-all-the-spreadsheets-recursively-with-their-tabs-sheets-info","title":"List All the Spreadsheets Recursively With Their Tabs (Sheets) Info","text":"<pre><code>files = google.drive.listSpreadsheets(folder_id, name_pattern='report', recursive_depth=1, with_meta=True, do_print=True)\n\nfor file in files:\n    google.drive.downloadFile(file['id'], do_print=True)\n</code></pre>"},{"location":"#download-export-files-and-spreadsheets-or-google-form-responses","title":"Download, Export Files and Spreadsheets or Google Form Responses","text":"<pre><code>google.drive.getFormMetadata(form_id)\n\ngoogle.drive.getFormResponses(form_id)\n\ngoogle.drive.getFormQuestions(form_id)\n\n# Export Google Form responses as CSV\ngoogle.drive.downloadFile(form_id)\n\n# Export Google Spreadsheet as LibreOffice Calc\ngoogle.drive.downloadFile(spreadsheet_id, 'my_folder/spreadsheet_name', as_mime_type=MimeType.SHEET_LIBRE_CALC)\n</code></pre>"},{"location":"#get-data-from-google-analytics-4","title":"Get Data from Google Analytics 4","text":"<pre><code># Past 28 days (minus 2 days of delay)\nstart_date = (datetime.now() - timedelta(days=29)).strftime('%Y-%m-%d')\nend_date = (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d')\n\nprops = google.analytics.listProperties()\n\nproperty_id = 'property_id'\n\ngoogle.analytics.fetchPages(property_id, start_date, end_date)\n\ngoogle.analytics.fetchTrafficStats(property_id, start_date, end_date)\n\ngoogle.analytics.fetchInternalSiteSearch(property_id, start_date, end_date)\n</code></pre>"},{"location":"#and-from-google-search-console-gsc","title":"And From Google Search Console (GSC)","text":"<pre><code>google.analytics.listGSCSites()\n\nsite = 'sc-domain:arkalos.com'\n\ngoogle.analytics.fetchTopGSCPages(site, start_date, end_date)\n\nqueries = google.analytics.fetchTopGSCQueries(site, start_date, end_date)\n\n# Sort by a built-in CTR Opportunity Score\npl.Config(tbl_rows=100)\npl.DataFrame(queries).select(pl.exclude('site', 'page_url', 'page_path')).sort('ctr_os', descending=True)\n\n# Fetch top pages first and then their top queries (Page-first)\ngoogle.analytics.fetchTopGSCPagesThenQueries(site, start_date, end_date)\n\n# Query-first\ngoogle.analytics.fetchTopGSCQueriesThenPages(site, start_date, end_date)\n\n# Or as sections, instead of a single table\ngoogle.analytics.fetchTopGSCPagesThenQueries(site, start_date, end_date, with_sections=True)\n</code></pre>"},{"location":"#beautiful-documentation-get-started-today","title":"Beautiful Documentation - Get Started Today","text":"<p>Read the Documentation</p>"},{"location":"#appreciations","title":"Appreciations","text":"<p>We are grateful to the communities behind these open-source projects on which we depend.</p>"},{"location":"#license","title":"License","text":"<p>MIT License.</p> <p>Check the LICENSE file for answers to common questions.</p>"},{"location":"appreciations/","title":"Appreciations","text":"<p>We are grateful to our community, sponsors, partners and friends, especially ATHENNO Corporation and Yinson Holdings Bhd.</p> <p>We are grateful to Taylor Otwell, Laravel, PHP and Node.js communities for some inspirations.</p> <p>We are grateful to the communities behind these open-source projects on which we depend:</p> <p>Core:</p> <ul> <li>Python language</li> <li>uv package manager</li> <li>Ollama</li> <li>Jupyter Notebook</li> </ul> <p>Core Python Libraries, Data &amp; Stats:</p> <ul> <li>python-dotenv</li> <li>numpy</li> <li>pandas</li> <li>polars</li> <li>datasets</li> <li>scipy</li> <li>nltk</li> <li>arrow</li> </ul> <p>ML/AI &amp; Models:</p> <ul> <li>scikit-learn</li> <li>PyTorch</li> <li>Transformers by Hugging Face</li> <li>Ollama</li> <li>qwen2.5-coder and qwen-based models</li> <li>DeepSeek-based models</li> </ul> <p>Data Visualization:</p> <ul> <li>matplotlib</li> <li>seaborn</li> <li>altair</li> </ul> <p>Web, HTTP &amp; Text Parsing:</p> <ul> <li>requests</li> <li>lxml</li> <li>beautifulsoup4</li> <li>playwright</li> <li>markdownify</li> <li>FastAPI</li> <li>uvicorn</li> </ul> <p>Dev, IDE, Data Generation &amp; Testing:</p> <ul> <li>pytest</li> <li>ipykernel</li> <li>mypy</li> <li>pydantic</li> <li>faker</li> </ul> <p>Clients &amp; APIs:</p> <ul> <li>google-api-python-client</li> </ul> <p>Typing:</p> <ul> <li>types-requests</li> <li>google-api-python-client-stubs</li> <li>lxml-stubs</li> <li>types-beautifulsoup4</li> </ul> <p>Documentation:</p> <ul> <li>mkdocs</li> <li>mkdocs-material</li> </ul>"},{"location":"contact/","title":"Contact or Follow Us and Join the Community","text":"<p>Arkalos is an independent open-source community project, not affiliated with any corporation.</p>"},{"location":"contact/#contact-follow","title":"Contact &amp; Follow","text":"<p>Creator &amp; Project Lead - Mev-Rael</p>"},{"location":"contact/#join-the-community-and-ask-questions","title":"Join the Community and Ask Questions","text":"<p>Join the Arkalos Community on X</p>"},{"location":"contact/#star-us-on-github-and-contribute","title":"Star Us on GitHub and Contribute","text":"<p>Arkalos GitHub repository</p>"},{"location":"legal/","title":"Legal &amp; License","text":"<p>Arkalos is licensed under the MIT license.</p>"},{"location":"legal/#the-project","title":"The Project:","text":"<p>Project \"Arkalos\" Copyright (c) Mev-Rael Anno 2025</p> <p>The primary purpose of Arkalos is to provide a universal Python framework that allows all individuals and entities to study, teach, develop, execute, or commercialize their projects, which are not limited to, but include: notebooks, scripts, data pipelines, ML workflows, AI agents, data apps, platforms, data warehouses, and the training of models, including LLMs.</p>"},{"location":"legal/#the-mit-license-mit","title":"The MIT License (MIT):","text":"<p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"legal/#mit-faq-annotation","title":"MIT FAQ &amp; Annotation:","text":"<p>The MIT License, established by the MIT in the late 1980s, is a permissive software license designed to facilitate free use, modification, sharing, and commercialization of software. Its primary goal is to foster collaboration and innovation by minimizing barriers to code reuse while ensuring proper attribution to authors and creators through the inclusion of the original copyright notice and license in any redistributions.</p> <p>Distribution means delivering software or part of it to end-users via various means, including physical media, online platforms, cloud services, app stores and virtual environments.</p> <p>If you develop a product that diverges from the original purpose of this software (e.g., a mobile app, SaaS platform, or custom software for monetization), you MUST only acknowledge the original author(s) by mentioning the software's name at the end of your legal documents (e.g., privacy policy, terms of service), in a dedicated section such as \"About\", \"Appreciations\" or \"Acknowledgments,\" or in other placements such as the website footer or a statement like: \"We are grateful to the communities behind these open-source projects on which we depend: [list software names or link to a dedicated page with this list].\" Optionally, include the author(s) and a link to the public repository for full license details. You do not have to disclose anything further or make your code public.</p> <p>Conversely, if you fork or create public derivative works based on the original software, you MUST retain the MIT License and include it along with the original copyright notice and this annotation.</p>"},{"location":"docs/ai-actions/","title":"AI Actions","text":"<p>AI Actions or Tasks are actions that AI Agents can perform. Some tasks are simple, like getting basic information, while others use AI models or external tools to process data.</p> <p>Arkalos provides built-in tasks like converting natural language to SQL, querying a data warehouse, and displaying data.</p> <p>Tasks are essential building blocks \u2014 without them, an AI Agent can't do anything.</p>"},{"location":"docs/ai-actions/#creating-an-action","title":"Creating an Action","text":"<p>Let's create two actions:</p> <ol> <li>Basic Action: Find the user's IP address.</li> <li>AI-Powered Action: A natural language calculator.</li> </ol>"},{"location":"docs/ai-actions/#basic-action-what-is-my-ip","title":"Basic Action: What is My IP","text":"<p>Create a new file: <code>app/ai/actions/what_is_my_ip_action.py</code></p> app/ai/tasks/what_is_my_ip_action.py<pre><code>import socket\nfrom arkalos.ai import AIAction\n\nclass WhatIsMyIpAction(AIAction):\n\n    NAME = 'what_is_my_ip'\n    DESCRIPTION = 'Get the user's IP address.'\n\n    def run(self, message):\n        hostname = socket.gethostname()\n        return socket.gethostbyname(hostname)\n</code></pre> <p>Every AI Action in Arkalos must implement the <code>AIAction</code> contract and three key properties/methods:</p> <ul> <li><code>NAME</code>: A unique name for the action.</li> <li><code>DESCRIPTION</code>: A clear and descriptive explanation of what the action does. Other actions and AI Agents can use this information to determine if the task is capable of processing a certain input.</li> <li><code>run(message)</code>: The main function that processes input and returns a result. We don't use user's input in this example.</li> </ul>"},{"location":"docs/ai-actions/#ai-action-natural-language-calculator","title":"AI Action: Natural Language Calculator","text":"<p>Create a new file: <code>app/ai/actions/calc_action.py</code></p> app/ai/tasks/calc_action.py<pre><code>from arkalos.ai import AIAction\n\nclass CalcTask(AIAction):\n\n    NAME = 'calc'\n    DESCRIPTION = 'Solve mathematical expressions from natural language.'\n\n    def run(self, message):\n        prompt = f\"\"\"\n            ### Instructions:\n            You are a calculator. Solve the following expression:\n\n            ### Input:\n            `{message}`\n\n            ### Response:\n            Return only the final numerical result.\n        \"\"\"\n        return self.generateTextResponse(prompt)\n</code></pre> <p>This action uses an AI model to process user input, generate a math formula, and return a single calculated value.</p> <p>The response time depends on your computer's CPU, RAM, GPU, and the AI model set in the <code>.env</code> file.</p>"},{"location":"docs/ai-actions/#using-actions-in-an-agent","title":"Using Actions in an Agent","text":"<p>Now that we have actions, let\u2019s add them to an AI Agent! Learn how here \u2192</p>"},{"location":"docs/ai-agents/","title":"AI Agents","text":"<p>AI Agents are intelligent controllers that connect different tasks, process user input, and generate meaningful responses. They act like a human assistant.</p> <p>They can operate in different environments, such as a command-line console, a web browser, a virtual gaming world or simulation, or even a real physical world like robots and autonomous vehicles.</p> <p>Arkalos includes built-in AI Agents like <code>DWHAgent</code>, which allows users to interact with their data using natural language.</p> <p>Let's create our own AI Agent.</p>"},{"location":"docs/ai-agents/#creating-an-ai-agent","title":"Creating an AI Agent","text":"<p>To create an agent, implement the <code>AIAgent</code> contract and define the following methods:</p> <ul> <li><code>NAME</code>: A unique name for the agent.</li> <li><code>DESCRIPTION</code>: A brief explanation of what the agent does.</li> <li><code>GREETING</code>: Initial greeting message from the agent to the user.</li> <li><code>ACTIONS</code>: List of actions an agent can take.</li> <li><code>processMessage(message)</code>: The method that processes user input and runs actions.</li> </ul> <p>Note</p> <p>The AI Agent's <code>processMessage(message)</code> method expects a markdown-formatted string and returns a response as plain text or markdown. Using markdown enables frontend formatting for user-agent communication.</p>"},{"location":"docs/ai-agents/#example-simple-calculator-agent","title":"Example: Simple Calculator Agent","text":"<p>Create a new file: <code>app/ai/agents/my_agent.py</code></p> <pre><code>from arkalos.ai import AIAgent\nfrom app.ai.tasks.calc_action import CalcAction\n\nclass MyAgent(AIAgent):\n\n    NAME = 'MyAgent'\n\n    DESCRIPTION = 'A calculator agent.'\n\n    GREETING = 'Hi, I am a calculator. What do you want to calculate?'\n\n    ACTIONS = [\n        CalcAction\n    ]\n\n    def processMessage(self, message):\n        output = self.runAction(CalcAction, message)\n        return output\n</code></pre>"},{"location":"docs/ai-agents/#running-the-agent","title":"Running the Agent","text":"<p>Create a script and run the agent:</p> scripts/ai/my_agent.py<pre><code>from app.ai.agents.my_agent import MyAgent\n\nagent = MyAgent()\nagent.runConsole()\n</code></pre> <p>Run the script:</p> <pre><code>uv run scripts/ai/my_agent.py\n</code></pre>"},{"location":"docs/ai-agents/#multi-action-ai-agent","title":"Multi-Action AI Agent","text":"<p>A multi-task agent can determine user intent and execute the appropriate action.</p> <p>Arkalos includes a <code>whichAction()</code> method that uses AI to identify the correct task from the list of registered tasks.</p>"},{"location":"docs/ai-agents/#example-multi-task-ai-agent","title":"Example: Multi-Task AI Agent","text":"<pre><code>from arkalos.ai import AIAgent\nfrom app.ai.tasks.calc_action import CalcAction\nfrom app.ai.tasks.what_is_my_ip_action import WhatIsMyIpAction\n\nclass MultiAgent(AIAgent):\n\n    NAME = 'MultiAgent'\n\n    DESCRIPTION = 'An Agent that understands the intent, determines which task to perform and runs it.'\n\n    GREETING = 'Hi, I am a MultiAgent. I can tell your IP address, do basic math calculations or transform text to SQL.'\n\n    ACTIONS = [\n        WhatIsMyIpAction, \n        CalcAction, \n        TextToSQLAction\n    ]\n\n    def processMessage(self, message):\n        response = f\"Determining the intent and which task to run...\\n\"\n        which_action = self.whichAction(message)\n        response += f\"Based on your question, I determined this task: {which_action}\\n\"\n        response += f\"Running this task...\\n\"\n        output = self.runAction(which_action, message)\n        response += f\"Task output: {output}\\n\"\n        return response\n</code></pre> <p>Here, <code>whichAction()</code> determines the right task based on user input.</p> <p>Now, you can create AI Agents that handle multiple tasks efficiently!</p>"},{"location":"docs/ai-eval/","title":"AI Eval","text":"<p>Note</p> <p>Coming Soon! Follow us and join the community</p>"},{"location":"docs/ai-models/","title":"Training a Model","text":"<p>Note</p> <p>Coming Soon! Follow us and join the community</p>"},{"location":"docs/app/","title":"Python App and Modules","text":"<p>Writing app code is more than just coding \u2014 it's a mindset. It\u2019s about designing code that\u2019s easy to grow, share, reuse and maintain.</p> <p>When you're writing Code to Run, like a notebook for quick data analysis or migration, you focus on getting the task done. But when writing Code to Reuse, you need to design it so it\u2019s easy for you and others \u2014 like your teammates, teachers, managers, or professors \u2014 to integrate into scripts and notebooks.</p> <p>Reusable code should avoid direct outputs like <code>print()</code> or charts. Instead, return values that can be used elsewhere. For example, if you generate a chart, consider returning it as an encoded string, making it flexible for various uses.</p> <p>Think of reusable code like Lego blocks \u2014 modular pieces that fit together seamlessly.</p>"},{"location":"docs/app/#modules-and-packages","title":"Modules and Packages","text":"<p>In Python, app code revolves around two key concepts: Modules and Packages.</p>"},{"location":"docs/app/#creating-modules","title":"Creating Modules","text":"<p>A module is any Python file (<code>.py</code>) that contains definitions \u2014 functions, classes, or constants \u2014 that you can import into scripts or notebooks.</p> <p>Previously, we created this module:</p> app/utils/my_utils.py<pre><code>from arkalos import config\n\ndef greet(greeting: str) -&gt; None:\n    print(f\"{greeting}, {config('app.name')}\")\n</code></pre> <p>Now we can rewrite it to follow the Code to Reuse mindset:</p> app/utils/my_utils.py<pre><code>from arkalos import config\n\ndef greet(greeting: str) -&gt; str:\n    return f\"{greeting}, {config('app.name')}\"\n</code></pre> <p>Notice how <code>greet()</code> now returns a string instead of printing it. This makes the function more versatile. You can print the result if needed:</p> <pre><code>print(greet('Hi'))\n</code></pre> <p>Or compose it with other functions:</p> app/utils/my_utils.py<pre><code>from arkalos import config\n\ndef greet(greeting: str) -&gt; str:\n    return f\"{greeting}, {config('app.name')}\"\n\ndef bye(hello_message: str, goodbye_message: str) -&gt; str:\n    return f\"{hello_message}. {goodbye_message}\"\n</code></pre> <p>Now, use these in a notebook:</p> notebooks/my_notebook.ipynb<pre><code>from app.utils.my_utils import greet, bye\n\nprint(bye(greet('Hi'), 'Goodbye!'))\n# Output: Hi, &lt;your app name&gt;. Goodbye!\n</code></pre> <p>By designing functions to return values, you make them flexible building blocks for larger workflows.</p>"},{"location":"docs/app/#creating-packages","title":"Creating Packages","text":"<p>A package is a folder containing modules and an optional <code>__init__.py</code> file. The <code>__init__.py</code> file helps organize imports, making it easier to access functions.</p> <p>For example, let\u2019s create a package:</p> <ol> <li> <p>Create the folder structure:</p> <pre><code>app/utils/my_package/\n    __init__.py\n    module_one.py\n    module_two.py\n</code></pre> </li> <li> <p>Add functions to the modules:</p> app/utils/my_package/module_one.py<pre><code>def add(a: int, b: int) -&gt; int:\n    return a + b\n\ndef subtract(a: int, b: int) -&gt; int:\n    return a - b\n</code></pre> app/utils/my_package/module_two.py<pre><code>def multiply(a: int, b: int) -&gt; int:\n    return a * b\n\ndef divide(a: int, b: int) -&gt; float:\n    return a / b\n</code></pre> </li> <li> <p>Organize imports in <code>__init__.py</code>:</p> app/utils/my_package/__init__.py<pre><code>from app.utils.my_package.module_one import add, subtract\nfrom app.utils.my_package.module_two import multiply, divide\n</code></pre> </li> </ol> <p>Now, you can import the whole package easily:</p> notebooks/my_notebook.ipynb<pre><code>from arkalos import var_dump\nimport app.utils.my_package as my_package\n\nvar_dump(my_package.add(5, 3))       # Output: int(8)\nvar_dump(my_package.divide(10, 2))   # Output: float(5.0)\n</code></pre> <p>No need to import each module individually \u2014 your package handles that for you!</p> <p>Note</p> <p>External packages (installed via <code>uv add &lt;package&gt;</code>) are more complex and aren\u2019t covered here. Publishing your own external packages involves additional steps like using a <code>src/</code> folder and registering with PyPI.</p>"},{"location":"docs/app/#functions-vs-classes","title":"Functions vs Classes","text":""},{"location":"docs/app/#when-to-use-functions","title":"When to Use Functions","text":"<p>Start with functions for simple, reusable tasks. Good functions:</p> <ul> <li>Take simple inputs</li> <li>Return simple outputs</li> <li>Do one thing well</li> <li>Avoid side effects (don\u2019t modify external states)</li> </ul> <p>Keep functions short and focused.</p>"},{"location":"docs/app/#when-to-use-classes","title":"When to Use Classes","text":"<p>Use classes when you need to define custom data types or enforce structure in your code.</p>"},{"location":"docs/app/#classes-for-custom-data-types","title":"Classes for Custom Data Types","text":"<p>If you need to represent a structured data, use the <code>@dataclass</code> decorator.</p> <p>A Python decorator is like a magical spell you can put on a function or a class to change how it works without changing the function itself. A decorator is like adding a honking device to the car without touching its engine!</p> <p>A dataclass decorator is like a special kind of toy box where you can put different toys (data) in an organized way.</p> app/data/types/point.py<pre><code>from dataclasses import dataclass\n\n@dataclass\nclass Point:\n    x: int\n    y: int\n</code></pre> notebooks/my_notebook.ipynb<pre><code>from arkalos import var_dump\n\nfrom app.data.types.point import Point\n\nmy_point = Point(3, 5)\nvar_dump(my_point)\n</code></pre> <p>This defines a custom <code>Point</code> data type.</p> <p>You can pass data in this format as arguments of functions across your workflows.</p>"},{"location":"docs/app/#classes-for-contracts-interfaces","title":"Classes for Contracts (Interfaces)","text":"<p>To enforce a consistent structure, use abstract classes as contracts (also called interfaces).</p> app/utils/greeter.py<pre><code>from abc import ABC, abstractmethod\n\nclass Greeter(ABC):\n    @abstractmethod\n    def myAction(self, greeting: str) -&gt; str:\n        pass\n</code></pre> <p><code>Greeter</code> is an abstract base class. It defines the method <code>myAction</code>, but doesn\u2019t implement it.</p> <p>Now, implement this contract in a concrete class:</p> app/utils/my_greeter.py<pre><code>from app.utils.greeter import Greeter\n\nclass MyGreeter(Greeter):\n    def myAction(self, greeting: str) -&gt; str:\n        return f\"{greeting}, from MyGreeter!\"\n</code></pre> <p>And use it in your notebook:</p> notebooks/my_notebook.ipynb<pre><code>from app.utils.my_greeter import MyGreeter\n\ngreeter = MyGreeter()\nprint(greeter.myAction('Hello'))\n# Output: Hello, from MyGreeter!\n</code></pre> <p>Using abstract classes ensures that everyone on your team follows the same structure, making your codebase more consistent and easier to maintain.</p>"},{"location":"docs/app/#what-next","title":"What Next","text":"<p>Now that you know how to structure your app code with modules, packages, functions, and classes, you\u2019re set to build reusable, maintainable Python projects and learn about Working as a Team</p>"},{"location":"docs/browser/","title":"Python Browser Automation","text":""},{"location":"docs/browser/#configuration","title":"Configuration","text":"<p>Arkalos makes it easy to automate the web using a real browser. You can use it for scraping, crawling, or saving web pages as Markdown. It\u2019s built on top of Microsoft\u2019s Playwright engine \u2014 a modern and fast automation library that supports all major browsers.</p> <p>Playwright works by controlling a real browser (like Edge or Chrome), either in a headless mode (without UI) or with a visible window. It follows web standards and provides a powerful and clean API, like <code>query_selector_all()</code> to get multiple elements from the page.</p> <p>You can use Arkalos to:</p> <ul> <li>Automate your browser while you're logged in</li> <li>Interact with dynamic websites</li> <li>Extract specific data</li> <li>Scroll pages like a real user</li> </ul> <p>Before using browser features, make sure to install Playwright\u2019s browsers and system dependencies:</p> <p>Note</p> <p>Chrome and Edge will be installed globally and might overwrite your current browser installation. If you already have them installed, you can install only specific browsers. If you are inside WSL or server, install all of them.</p> VS Code terminal - inside the Arkalos project<pre><code>playwright install --with-deps\n</code></pre> <p>If you don\u2019t have the Playwright Python module yet, add it to your project:</p> <pre><code>uv add playwright\n</code></pre>"},{"location":"docs/browser/#for-windows-and-wsl-users","title":"For Windows and WSL Users","text":"<p>If you're using WSL (Windows Subsystem for Linux), Playwright may not be able to connect to your browser running in Windows. You might see timeout errors when launching a browser.</p> <p>To fix this, switch WSL's networking mode to mirrored, which lets your WSL environment access services running on Windows.</p> <p>Follow these steps:</p> <ol> <li>Create a <code>.wslconfig</code> file in your Windows user directory (e.g., <code>C:\\Users\\YourUsername</code>)</li> <li> <p>Add this content: C:\\Users\\YourUsername\\.wslconfig<pre><code>[wsl2]\nnetworkingMode=mirrored\n</code></pre></p> </li> <li> <p>Close all running VS Code and WSL terminals.</p> </li> <li> <p>Restart WSL from the Windows Terminal (Admin): <pre><code>wsl --shutdown\n</code></pre></p> </li> <li> <p>Reopen VS Code and your project inside WSL.</p> </li> <li>Verify that WSL is using the mirrored networking mode: <pre><code>wslinfo --wsl-version\nwslinfo --networking-mode\n</code></pre></li> </ol>"},{"location":"docs/browser/#connecting-to-and-automating-your-real-browser","title":"Connecting to and Automating Your Real Browser","text":"<p>Sometimes, you want to automate a live browser that's already running, for example to:</p> <ul> <li>Skip login steps</li> <li>Avoid CAPTCHAs</li> <li>Access pages where you're already authenticated</li> </ul> <p>Arkalos supports this by connecting to browsers using the Chromium DevTools Protocol (CDP)\u2014a remote debugging protocol supported by Edge and Chrome.</p> <p>Note</p> <p>Only Chromium-based browsers like Chrome or Edge support CDP.</p>"},{"location":"docs/browser/#launching-your-browser-in-cdp-mode","title":"Launching Your Browser in CDP Mode","text":"<p>To enable CDP, you need to start your browser with a special flag that opens a remote debugging port.</p> <p>On Windows:</p> Windows Terminal (Admin)<pre><code>start msedge --remote-debugging-port=9222\n\n# or Chrome\nstart chrome --remote-debugging-port=9222\n</code></pre> <p>On macOS:</p> Mac Terminal<pre><code>sudo /Applications/Microsoft\\ Edge.app/Contents/MacOS/Microsoft\\ Edge --remote-debugging-port=9222\n\n# or Chrome\nsudo /Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome --remote-debugging-port=9222\n</code></pre>"},{"location":"docs/browser/#creating-a-webbrowser-and-running-an-action","title":"Creating a WebBrowser and Running an Action","text":"<p>Once your browser is running in CDP mode and you're logged in, you can connect to it using Arkalos.</p> <p>Use the <code>WebBrowser</code> class to launch or connect to a browser. By default, it creates a headless Edge browser. To connect to your live browser, use <code>REMOTE_CDP</code> type.</p> <p>Available browser types are defined inside <code>WebBrowser.TYPE</code>:</p> <ul> <li><code>REMOTE_CDP</code> \u2013 Connects to a running Chrome/Edge instance</li> <li><code>EDGE_HEADLESS</code> (default)  </li> <li><code>EDGE_UI</code> </li> <li><code>CHROME_HEADLESS</code> </li> <li><code>CHROME_UI</code> </li> <li><code>FIREFOX_HEADLESS</code> </li> <li><code>FIREFOX_UI</code> </li> <li><code>SAFARI_HEADLESS</code> </li> <li><code>SAFARI_UI</code> </li> </ul> notebooks/my_live_browser_automation.ipynb<pre><code>from arkalos.browser import WebBrowser, WebBrowserTab\n\nbrowser = WebBrowser(WebBrowser.TYPE.REMOTE_CDP)\n\nasync def search_google(tab: WebBrowserTab):\n    await tab.goto('https://www.google.com')\n    search_input = tab.get_by_role('combobox', name='Search')\n    await search_input.click()\n    await search_input.fill('cats')\n    await search_input.press('Enter')\n    images_tab = tab.get_by_role('link', name='Images', exact=True)\n    await images_tab.click()\n\nawait browser.run(search_google)\n</code></pre> <p>Note</p> <p>Arkalos uses async/await syntax. If you're working in a Jupyter notebook, you can use <code>await</code> directly. For regular Python scripts, wrap it with <code>asyncio.run()</code>.</p> <p>This example will open your real browser and run a search on Google, just like a user would.</p> <p>You can pass more arguments to the <code>run()</code> callback and return data from it. The <code>tab</code> parameter gives you full control of the browser page.</p>"},{"location":"docs/browser/#impersonation","title":"Impersonation","text":"<p>When you create a <code>WebBrowser</code>, Arkalos automatically sets:</p> <ul> <li>Correct headers</li> <li>User agent strings</li> <li>Browser behaviors</li> </ul> <p>This helps you avoid detection or errors when interacting with modern websites.</p>"},{"location":"docs/browser/#testing-headers-user-agent-ip-and-cookies","title":"Testing Headers, User Agent, IP, and Cookies","text":"<p>To debug or inspect what your browser is sending, use this utility:</p> notebooks/browser.ipynb<pre><code>test = await WebBrowser().testHeadersCookiesIP()\nheaders = test['headers']\ncookies = test['cookies']\nip = test['origin']\n</code></pre> <p>This tells you:</p> <ul> <li>What headers are being sent</li> <li>The cookies stored</li> <li>Your current IP address</li> </ul> <p>Useful for testing VPNs, proxies, or impersonation setup.</p>"},{"location":"docs/browser/#scrolling","title":"Scrolling","text":"<p>Many modern websites load content as you scroll. Arkalos supports smooth, human-like scrolling with <code>WebBrowser.scroll(tab)</code>.</p> <p>Use it inside your automation callback:</p> notebooks/browser.ipynb<pre><code>async def handle_page(tab: WebBrowserTab):\n    WebBrowser.scroll(tab)\n    ...\n</code></pre> <p>This helps trigger lazy-loaded content or infinite scroll.</p>"},{"location":"docs/con-google/","title":"Python Google Extractor API","text":""},{"location":"docs/con-google/#create-a-google-oauth-key","title":"Create a Google OAuth Key","text":"<p>(1)</p> <p>Create a new Google Cloud Console project, e.g. \"My Drive\"</p> <p>(2)</p> <p>Open \"APIs &amp; Services\", find and enable these APIs:</p> <ul> <li>Google Drive API</li> <li>Google Sheets API </li> <li>Google Forms API</li> <li>Google Search Console API </li> <li>Google Analytics Admin API</li> <li>Google Analytics Data API </li> </ul> <p>(3)</p> <p>Setup OAuth consent screen and select User Type = Internal.</p> <p>Enter your gmail into User support email, Developer contact information and/or Testing Users.</p> <p>Into any Domain, URL, Authorized JavaScript origins, redirect URIs, etc, enter - http://localhost</p> <p>(4)</p> <p>Go to \"Credentials\" and create new credentials for OAuth client ID.</p> <p>Select Application type - Desktop app, and provide a name for your app, e.g. \"My Personal Drive Desktop OAuth\"</p> <p>A pop-up will display your Client ID and Client Secret. Download them as a JSON file by clicking Download JSON.</p> <p>(5)</p> <p>Rename the file as <code>google_oauth.json</code> and put it into <code>data/keys/</code> folder.</p>"},{"location":"docs/con-google/#examples","title":"Examples","text":"<p>Create a new notebook and try the GoogleExtractor out!</p> <p>In the first cell, create a GoogleExtractor.</p> <pre><code>import polars as pl\n\nfrom arkalos.utils import MimeType\nfrom arkalos.data.extractors import GoogleExtractor\n\ngoogle = GoogleExtractor()\n</code></pre> <p>Run a cell. It will output a link for you to open in the browser.</p> <p>Enable all scopes.</p> <p>New <code>data/tokens/google_access_token.json</code> file will be then created. Next time authorization won't be required.</p> <p>If you need to change scopes or update the token - delete this file.</p>"},{"location":"docs/con-google/#search-and-list-google-drive-files-spreadsheets-and-forms","title":"Search and List Google Drive Files, Spreadsheets and Forms","text":"<pre><code>folder_id = 'folder_id'\n\n# List files and their metadata in a Google Drive folder\nfiles = google.drive.listFiles(folder_id)\n\n# Search for files with regex and by type\nfiles = google.drive.listFiles(folder_id, name_pattern='report', file_types=[MimeType.DOC_PDF])\n\nprint(pl.DataFrame(files))\n</code></pre>"},{"location":"docs/con-google/#list-all-the-spreadsheets-recursively-with-their-tabs-sheets-info","title":"List All the Spreadsheets Recursively With Their Tabs (Sheets) Info","text":"<pre><code>files = google.drive.listSpreadsheets(folder_id, name_pattern='report', recursive_depth=1, with_meta=True, do_print=True)\n\nfor file in files:\n    google.drive.downloadFile(file['id'], do_print=True)\n</code></pre>"},{"location":"docs/con-google/#download-export-files-and-spreadsheets-or-google-form-responses","title":"Download, Export Files and Spreadsheets or Google Form Responses","text":"<pre><code>google.drive.getFormMetadata(form_id)\n\ngoogle.drive.getFormResponses(form_id)\n\ngoogle.drive.getFormQuestions(form_id)\n\n# Export Google Form responses as CSV\ngoogle.drive.downloadFile(form_id)\n\n# Export Google Spreadsheet as LibreOffice Calc\ngoogle.drive.downloadFile(spreadsheet_id, 'my_folder/spreadsheet_name', as_mime_type=MimeType.SHEET_LIBRE_CALC)\n</code></pre>"},{"location":"docs/con-google/#get-data-from-google-analytics-4","title":"Get Data from Google Analytics 4","text":"<pre><code># Past 28 days (minus 2 days of delay)\nstart_date = (datetime.now() - timedelta(days=29)).strftime('%Y-%m-%d')\nend_date = (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d')\n\nprops = google.analytics.listProperties()\n\nproperty_id = 'property_id'\n\ngoogle.analytics.fetchPages(property_id, start_date, end_date)\n\ngoogle.analytics.fetchTrafficStats(property_id, start_date, end_date)\n\ngoogle.analytics.fetchInternalSiteSearch(property_id, start_date, end_date)\n</code></pre>"},{"location":"docs/con-google/#and-from-google-search-console-gsc","title":"And From Google Search Console (GSC)","text":"<pre><code>google.analytics.listGSCSites()\n\nsite = 'sc-domain:arkalos.com'\n\ngoogle.analytics.fetchTopGSCPages(site, start_date, end_date)\n\nqueries = google.analytics.fetchTopGSCQueries(site, start_date, end_date)\n\n# Sort by a built-in CTR Opportunity Score\npl.Config(tbl_rows=100)\npl.DataFrame(queries).select(pl.exclude('site', 'page_url', 'page_path')).sort('ctr_os', descending=True)\n\n# Fetch top pages first and then their top queries (Page-first)\ngoogle.analytics.fetchTopGSCPagesThenQueries(site, start_date, end_date)\n\n# Query-first\ngoogle.analytics.fetchTopGSCQueriesThenPages(site, start_date, end_date)\n\n# Or as sections, instead of a single table\ngoogle.analytics.fetchTopGSCPagesThenQueries(site, start_date, end_date, with_sections=True)\n</code></pre>"},{"location":"docs/configuration/","title":"Python Project Configuration and Environment Setup","text":"<p>Arkalos uses environment variables and configuration files to manage settings across your entire app and any workflow, script or notebook.</p> <p>You can get env variables via <code>env('KEY')</code> function.</p> <p>Or config settings via <code>config('config_file.key')</code>.</p>"},{"location":"docs/configuration/#environment-variables-env","title":"Environment Variables (<code>.env</code>)","text":"<p>When you start an Arkalos project, you'll notice two environment files:</p> <ol> <li>.env.example - A template file with sample environment variables.</li> <li>.env - Your actual configuration file, which is gitignored to prevent sensitive data from being committed to version control.</li> </ol> <p>Whenever you add a new custom env variable, add an empty or default value to the <code>.env.example</code> as well so your team would know about them.</p>"},{"location":"docs/configuration/#why-use-environment-variables","title":"Why Use Environment Variables?","text":"<p>Environment variables allow you to:</p> <ul> <li>Secure sensitive data like API keys, database credentials, and tokens.</li> <li>Easily switch between environments, such as local development and production servers, by changing the settings in your <code>.env</code> file.</li> <li>Collaborate with teams without sharing sensitive credentials \u2014 team members can use the <code>.env.example</code> file as a reference.</li> </ul>"},{"location":"docs/configuration/#example-env-file","title":"Example <code>.env</code> File","text":"<pre><code># - MAIN / APP -\nAPP_NAME=My App\nAPP_ENV=local\nAPP_KEY=generated automatically\n\n# - DATA WAREHOUSE -\nDWH_ENGINE=SQLite\nDWH_SCHEMA_PATH=data/dwh/schema.sql\nDWH_SQLITE_PATH=data/dwh/dwh.db\n# DWH_HOST=127.0.0.1\n# DWH_PORT=3306\n# DWH_DATABASE=warehouse\n# DWH_USERNAME=root\n# DWH_PASSWORD=\n\n# - LLM (Models available on Ollama) -\nLLM=qwen2.5-coder\n# LLM=deepseek-r1:1.5b\n# LLM=deepseek-r1:7b\n\n# - DATA SOURCES (CONNECTORS / EXTRACTORS) -\nAIRTABLE_API_KEY=\nAIRTABLE_BASE_ID=\nAIRTABLE_TABLES='[\n    {\"id\": \"\", \"name\": \"\"},\n]'\n\nGOOGLE_SERVICE_ACCOUNT_KEY_PATH=data/keys/gdrive.json\nGOOGLE_SPREADSHEETS=\n\nNOTION_API_SECRET=\nNOTION_DATABASES=\n\nMONDAY_API_KEY=\nMONDAY_TABLES=\n\nHUBSPOT_API_KEY=\n\n# - LLM &amp; AI API KEYS -\nDEEPSEEK_API_KEY=\n\nOPENAI_API_KEY=\n</code></pre> <p>Note</p> <p>Some environment variables contain JSON strings. Make sure:</p> <ul> <li>The JSON is valid.</li> <li>Use single quotes around the entire string and double quotes inside the JSON.</li> <li>Pay attention to commas: no trailing commas after the last item.</li> </ul>"},{"location":"docs/configuration/#configuration-files","title":"Configuration Files","text":"<p>Arkalos uses Python-based configuration files stored in the <code>config/</code> folder. Unlike traditional text-based config files (like <code>.json</code> or <code>.yaml</code>), Python config files allow you to:</p> <ul> <li>Use functions and logic inside the configuration.</li> <li>Dynamically load environment variables using the <code>env()</code> function.</li> </ul>"},{"location":"docs/configuration/#available-config-files","title":"Available Config Files","text":"<ol> <li>config/app.py - General app settings.</li> <li>config/data_sources.py - Configurations for data connectors (Airtable, Google Sheets, etc.).</li> <li>config/data_warehouse.py - Data warehouse settings (SQLite, PostgreSQL, etc.).</li> </ol>"},{"location":"docs/configuration/#example-configurations","title":"Example Configurations","text":""},{"location":"docs/configuration/#configapppy","title":"<code>config/app.py</code>","text":"<pre><code>from arkalos import env\n\nconfig = {\n    'name': env('APP_NAME', 'Arkalos App'),\n    'env': env('APP_ENV', 'production'),\n    'llm': env('LLM', 'qwen2.5-coder'),\n    'debug': env('APP_DEBUG', False),\n}\n</code></pre>"},{"location":"docs/configuration/#configdata_sourcespy","title":"<code>config/data_sources.py</code>","text":"<pre><code>from arkalos import env\n\nconfig = {\n    'airtable': {\n        'enabled': False,\n        'api_key': env('AIRTABLE_API_KEY'),\n        'base_id': env('AIRTABLE_BASE_ID'),\n        'tables': env('AIRTABLE_TABLES'),\n    },\n    'google': {\n        'enabled': False,\n        'service_account_key_path': env('GOOGLE_SERVICE_ACCOUNT_KEY_PATH'),\n        'spreadsheets': env('GOOGLE_SPREADSHEETS'),\n        'id_col': 'id',\n        'updated_at_col': 'updated_at'\n    },\n    'hubspot': {\n        'enabled': False,\n        'api_key': env('HUBSPOT_API_KEY'),\n        'objects': ['contacts', 'companies', 'deals'],\n    },\n    'monday': {\n        'enabled': False,\n        'api_key': env('MONDAY_API_KEY'),\n        'databases': env('MONDAY_DATABASES'),\n    },\n    'notion': {\n        'enabled': False,\n        'api_secret': env('NOTION_API_SECRET'),\n        'databases': env('NOTION_DATABASES'),\n    },\n}\n</code></pre>"},{"location":"docs/configuration/#configdata_warehousepy","title":"<code>config/data_warehouse.py</code>","text":"<pre><code>from arkalos import env\n\nconfig = {\n    'engine': env('DWH_ENGINE', 'sqlite'),\n    'schema_path': env('DWH_SCHEMA_PATH', 'data/dwh/dwh.sql'),\n    'sync_frequency': '1h',\n\n    # SQLite\n    'path': env('DWH_SQLITE_PATH', 'data/dwh.db'),\n\n    # PostgreSQL, etc.\n    'host': env('DWH_HOST', '127.0.0.1'),\n    'port': env('DWH_PORT', '3306'),\n    'database': env('DWH_DATABASE', 'warehouse'),\n    'username': env('DWH_USERNAME', 'root'),\n    'password': env('DWH_PASSWORD', ''),\n\n    'engines': {\n        'sqlite': {},\n        # 'postgresql': {},\n        # 'bigquery': {},\n        # 'snowflake': {}\n    }\n}\n</code></pre>"},{"location":"docs/configuration/#creating-a-new-configuration-file","title":"Creating a New Configuration File","text":"<p>To add a new config file:</p> <ol> <li>Create a new Python file in the <code>config/</code> folder (e.g., <code>config/new_config.py</code>).</li> <li>Add the following structure:</li> </ol> <pre><code>from arkalos import env\n\nconfig = {\n    'key_name': env('ENV_VARIABLE', 'default_value'),\n    # Add more configurations here\n}\n</code></pre> <p>Now, your new configuration is ready to be used in your project.</p> <p>You can access it via <code>config('new_config.key_name')</code></p>"},{"location":"docs/configuration/#default-language-model-llm","title":"Default Language Model (LLM)","text":"<p>Choose which language model your app will use by default by specifying its name in the <code>.env</code> file:</p> <pre><code>LLM=qwen2.5-coder\n</code></pre> <p>If you followed previous installation guide, the <code>qwen2.5-coder</code> model from Ollama should already be set up on your system. This lightweight model works smoothly on a typical laptop or server with at least 8\u202fGB of RAM. It\u2019s good enough for basic chatting or generating code snippets.</p> <p>If your machine is more powerful (especially with a high-end GPU), feel free to switch to a larger model by simply changing the model name in your configuration. And when moving to production, we recommend using an enterprise server or cloud services with sufficient memory and GPU.</p>"},{"location":"docs/configuration/#data-sources-extractors-and-connectors","title":"Data Sources, Extractors and Connectors","text":"<p>Arkalos currently supports these providers out of the box:</p> <ul> <li>Notion (databases only)</li> <li>Airtable (tables)</li> </ul> <p>Google Drive, Monday.com, HubSpot and others are comming soon.</p> <p>For other data sources, You can create your own implementation by using the <code>DataExtractor</code> contract.</p>"},{"location":"docs/configuration/#notion","title":"Notion","text":"<p>Create a new Integration and API Secret by following the Notion guide.</p> <p>You must be an Owner or Admin of the workspace. Select your workspace and select type: Internal. Generate and copy a new secret into <code>.env</code> file.</p> .env (this is an example, not a valid real secret)<pre><code>NOTION_API_SECRET=ntn_3465436gigtw87wq4yNwugKGrhwefeiw7gtwogcyt\n</code></pre> <p>Now open a Notion database as a separate page that you wish to sync into your warehouse. For practice, you can create a new workspace and use the default Project and Tasks template. Copy the ID for each database you wish to sync. You can find the ID in the URL right after the domain:</p> <p>notion.so/<code>158a035340380c5a990dgfgwejfwef</code>?v=35g3k3tk4333yh3hy34996b</p> <p>Update the <code>.env</code> file and enter a new JSON row. Make sure there is no comma after the last item. Copy the ID and provide a name for each database. It can be any name you wish. Arkalos Data Warehouse will create a new table for each data source as <code>&lt;source_name&gt;__&lt;table_name&gt;</code>, e.g., <code>Notion__Tasks</code>.</p> .env<pre><code>NOTION_API_SECRET=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\nNOTION_DATABASES='[\n    {\"id\": \"158a035340380c5a990dgfgwejfwef\", \"name\": \"Tasks\"},\n    {\"id\": \"159a035340380c5a990dgfgwejfwef\", \"name\": \"Projects\"}\n]'\n</code></pre> <p>Finally, enable your integration on EACH database page.</p> <p>In the top right corner, from the \"...\" menu, select Connections and then search for and enable your new integration.</p>"},{"location":"docs/configuration/#airtable","title":"Airtable","text":"<p>In Airtable, under your user menu in the top right corner, open Builder Hub.</p> <p>Create a new Personal Access Token. Type any name for your integration. Select these two scopes:</p> <ul> <li><code>data.records:read</code></li> <li><code>schema.bases:read</code></li> </ul> <p>Under Access, select your Airtable workspace and save the token into <code>.env</code>. For practice, you may use Airtable AI App builder to generate a new app and tables with some data.</p> .env<pre><code>AIRTABLE_API_KEY=patHglggwgel.93IGLi5feih64da9c37853256gi75e4072d24353452g5ge\n</code></pre> <p>Open your workspace and copy the Base ID as well. It starts with \"app...\" and you can find it right after the domain:</p> <p>airtable.com/<code>appgJGkGY65KYrjf6fK</code>/tblhj3hk796wolwe7/viw5tuGutk8t6l</p> .env<pre><code>AIRTABLE_BASE_ID=appgJGkGY65KYrjf6fK\n</code></pre> <p>Finally, update the <code>.env</code> file and enter a new JSON row. Make sure there is no comma after the last item. Copy the ID and provide a name for each table from the URL (starts with \"tbl...\"). It can be any name you wish. Arkalos Data Warehouse will create a new table for each data source as <code>&lt;source_name&gt;__&lt;table_name&gt;</code>, e.g., <code>Airtable__Tasks</code>.</p> <p>airtable.com/appgJGkGY65KYrjf6fK/<code>tblhj3hk796wolwe7</code>/viw5tuGutk8t6l</p> .env<pre><code>AIRTABLE_TABLES='[\n    {\"id\": \"tblhj3hk796wolwe7\", \"name\": \"Tasks\"},\n    {\"id\": \"tblwj3hk796wolwe7\", \"name\": \"Projects\"}\n]'\n</code></pre>"},{"location":"docs/configuration/#data-warehouse","title":"Data Warehouse","text":"<p>Universal settings:</p> .env<pre><code>DWH_SCHEMA_PATH=data/dwh/schema.sql\n</code></pre> <ul> <li><code>DWH_SCHEMA_PATH</code>: Arkalos automatically generates and updates this file. It contains the SQL structure of your data. For example, when a new data source is synced into the warehouse, Arkalos infers the schema (data structure) automatically by analyzing the first rows of the incoming data.</li> </ul> <p>Engine-specific settings:</p> <p>Currently, only the SQLite engine is supported out of the box.</p> .env<pre><code>DWH_ENGINE=SQLite\nDWH_SQLITE_PATH=data/dwh/dwh.db\n</code></pre> <p>You can create your own implementation by using the <code>DataWarehouse</code> contract.</p> <p>You can access the data warehouse from any part of your notebook, script, or application:</p> <pre><code>from arkalos import dwh\n\ndwh().connect()\n</code></pre>"},{"location":"docs/configuration/#lets-write-our-first-arkalos-code","title":"Let's Write Our First Arkalos Code!","text":"<p>That's it! You have completed the Getting Started guide and are ready to write some code!</p>"},{"location":"docs/data-analyzers/","title":"Data Analyzers","text":"<p>Arkalos provides a flexible API for analyzing structured datasets. Its analyzers help uncover patterns, segment data, and visualize important trends using powerful visualizations built with Altair and Vega specifications.</p> <p>Currently available analyzers:</p> <ul> <li><code>ClusterAnalyzer</code> \u2013 for clustering, pattern recognition, and feature importance insights</li> </ul>"},{"location":"docs/data-analyzers/#clusteranalyzer","title":"ClusterAnalyzer","text":"<p>Clustering is an unsupervised learning method used to group similar data points together based on their characteristics. It\u2019s useful in many fields such as marketing segmentation, customer behavior analysis, anomaly detection, and recommendation systems.</p> <p>In Arkalos, <code>ClusterAnalyzer</code> simplifies the process of clustering and visualizing your data.</p>"},{"location":"docs/data-analyzers/#example-segmenting-a-marketing-campaign-dataset","title":"Example: Segmenting a Marketing Campaign Dataset","text":"<p>Let\u2019s walk through a step-by-step analysis of customer behavior using a marketing campaign dataset.</p>"},{"location":"docs/data-analyzers/#step-1-load-the-dataset","title":"\ud83d\udce5 Step 1: Load the Dataset","text":"<p>Download the marketing_campaign.csv dataset from Kaggle and save it under <code>data/drive</code> or your notebook's working directory.</p> notebooks/clustering.ipynb (cell 1)<pre><code>import polars as pl\nfrom arkalos import drive_path\nfrom arkalos.data.analyzers import ClusterAnalyzer\nfrom arkalos.data.transformers import DataTransformer\n\ndf = pl.read_csv(drive_path('marketing_campaign.csv'), separator='\\t')\n</code></pre>"},{"location":"docs/data-analyzers/#step-2-preprocess-and-clean-the-data","title":"\ud83e\uddf9 Step 2: Preprocess and Clean the Data","text":"<p>Before clustering, clean and prepare the dataset using <code>DataTransformer</code>.</p> notebooks/clustering.ipynb (cell 2)<pre><code>dtf = (DataTransformer(df)\n    .renameColsSnakeCase()\n    .dropRowsByID(9432)\n    .dropCols(['id', 'dt_customer'])\n    .dropRowsDuplicate()\n    .dropRowsNullsAndNaNs()\n    .dropColsSameValueNoVariance()\n    .splitColsOneHotEncode(['education', 'marital_status'])\n)\n\ncln_df = dtf.get()  # Get cleaned Polars DataFrame\n\nprint(f'Dataset shape: {cln_df.shape}')\ncln_df.head()\n</code></pre>"},{"location":"docs/data-analyzers/#step-3-correlation-heatmap-with-altair","title":"\ud83d\udcca Step 3: Correlation Heatmap with Altair","text":"<p>Visualize relationships between numerical features using a correlation heatmap.</p> notebooks/clustering.ipynb (cell 3)<pre><code>ca = ClusterAnalyzer(cln_df)\nca.createCorrHeatmap()\n</code></pre> <p></p> <p>This heatmap helps identify redundant or highly correlated features to consider removing or combining before clustering.</p>"},{"location":"docs/data-analyzers/#step-4-hierarchical-clustering-and-dendrogram","title":"\ud83c\udf3f Step 4: Hierarchical Clustering and Dendrogram","text":"<p>To estimate the optimal number of clusters, start with Agglomerative Hierarchical Clustering and plot the dendrogram.</p> notebooks/clustering.ipynb (cell 4)<pre><code>n_clusters = ca.findNClustersViaDendrogram()\nprint(f'Optimal clusters (dendrogram): {n_clusters}')\n\nca.createDendrogram()\n</code></pre> <p></p> <p>The dendrogram shows how clusters are merged and suggests an optimal cluster count where vertical lines (distance) are largest.</p>"},{"location":"docs/data-analyzers/#step-5-elbow-plot-k-means-diagnostic","title":"\ud83d\udcc8 Step 5: Elbow Plot (K-Means Diagnostic)","text":"<p>Another common technique to estimate the number of clusters is the elbow method, which plots total within-cluster variance.</p> notebooks/clustering.ipynb (cell 5)<pre><code>n_clusters = ca.findNClustersViaElbow()\nprint(f'Optimal clusters (elbow): {n_clusters}')\n\nca.createElbowPlot()\n</code></pre> <p></p> <p>The \u201celbow\u201d point marks the optimal cluster count where adding more clusters yields diminishing returns.</p>"},{"location":"docs/data-analyzers/#step-6-perform-hierarchical-clustering","title":"\ud83e\uddec Step 6: Perform Hierarchical Clustering","text":"<p>Use the selected number of clusters to perform bottom-up agglomerative clustering:</p> notebooks/clustering.ipynb (cell 6)<pre><code>n_clusters = 3\nca.clusterHierarchicalBottomUp(n_clusters)\n</code></pre>"},{"location":"docs/data-analyzers/#step-7-cluster-bar-chart-grid-feature-importance","title":"\ud83d\udcca Step 7: Cluster Bar Chart Grid (Feature Importance)","text":"<p>After clustering, visualize which features differentiate each cluster using an interactive bar chart grid, sorted by Gini importance:</p> notebooks/clustering.ipynb (cell 7)<pre><code>ca.createClusterBarChart()\n</code></pre> <p></p> <p>Each subplot corresponds to a feature; bars represent average values per cluster.</p>"},{"location":"docs/data-analyzers/#step-8-summary-report","title":"\ud83d\udccb Step 8: Summary Report","text":"<p>Print a human-readable summary showing the most informative features for each cluster.</p> notebooks/clustering.ipynb (cell 8)<pre><code>ca.printSummary()\n</code></pre> <p></p> <p>Each cluster's profile includes min, max, average, and standard deviation for each feature.</p>"},{"location":"docs/data-analyzers/#k-means-clustering","title":"K-Means Clustering","text":"<p>Compare hierarchical clustering with K-Means, a partition-based method often faster for large datasets.</p> notebooks/clustering.ipynb (cell 9)<pre><code>ca_kmeans = ClusterAnalyzer(cln_df)\nca_kmeans.clusterKMeans(3)\nca_kmeans.createClusterBarChart()\n</code></pre> notebooks/clustering.ipynb (cell 10)<pre><code>ca_kmeans.printSummary()\n</code></pre> <p>Notice how different clustering methods may yield different insights depending on the dataset's structure.</p>"},{"location":"docs/data-sources/","title":"Data Sources","text":"<p>Note</p> <p>Coming Soon! Follow us and join the community</p>"},{"location":"docs/data-transformers/","title":"Data Transformers","text":"<p>Note</p> <p>Coming Soon! Follow us and join the community</p>"},{"location":"docs/data-visualizers/","title":"Data Visualizers","text":"<p>Note</p> <p>Coming Soon! Follow us and join the community</p>"},{"location":"docs/data-warehouse/","title":"Data Warehouse","text":"<p>Note</p> <p>Coming Soon! Follow us and join the community</p>"},{"location":"docs/deployment/","title":"Deploying Python Projects and Scripts with GitHub Actions to DigitalOcean","text":"<p>In this guide, you'll learn how to set up automatic deployment for your Python app using GitHub Actions and DigitalOcean. This is a one-time setup: once it\u2019s done, you can deploy updates just by pushing code to your repository with <code>git push</code>.</p>"},{"location":"docs/deployment/#create-a-github-repository","title":"Create a GitHub Repository","text":"<p>If you don\u2019t already have a GitHub repository:</p> <ol> <li>Go to GitHub and click the + New repository button in the top-left corner.</li> <li>Choose your personal account or organization.</li> <li>Name your repository (e.g. <code>arkalos-app</code>).</li> <li>Set it to Private.</li> <li>Skip other options and click Create repository.</li> <li>Push your local project to this repository:</li> </ol> <pre><code># If you haven\u2019t initialized Git commits yet:\ngit add .\ngit commit -m \"init\"\n\n# Set main branch and push to GitHub\ngit branch -M main\ngit remote add origin git@github.com:your-username/your-repo.git # copy link from GitHub\ngit push -u origin main\n</code></pre> <p>Refresh your GitHub repository page \u2014 you should see your project files.</p>"},{"location":"docs/deployment/#set-up-a-digitalocean-droplet","title":"Set Up a DigitalOcean Droplet","text":"<ol> <li>Sign up at DigitalOcean and create a Team and Project.</li> <li>Rename the project in the sidebar to something like <code>arkalos-app</code>.</li> <li>Click Spin up a Droplet.</li> <li>Choose a region close to you.</li> <li>Under Choose an image, select Ubuntu 24.04 (LTS) x64.</li> <li>Choose the Basic (CPU Options: Regular) plan. Only $4/month. Or you may choose the cheapest Premium Intel option for $8/month with more power and space. If you plan to have a larger application and use AI, you will have to pick a larger option.</li> <li>Skip other options and under Authentication Method, select SSH Key and click Add SSH Key.</li> <li>If you don\u2019t have an SSH key:<ul> <li>Run <code>ssh-keygen</code> in your terminal (on VS Code/WSL).</li> <li>Copy the contents of <code>~/.ssh/id_rsa.pub</code> into the box.</li> <li>Name it something like \"Your Laptop SSH Key\".</li> </ul> </li> <li>Check the Add improved metrics monitoring and alerting (free)</li> <li>Under the \"Advanced Options\" select Enable IPv6 (free).</li> <li>Set a hostname (e.g. <code>arkalos-app</code> or with your domain such as <code>dashboard.arkalos.com</code>).</li> <li>Keep quantity 1 and click Create Droplet. Once the droplet is ready, you\u2019ll see a green dot indicating it\u2019s active.</li> </ol>"},{"location":"docs/deployment/#add-a-domain-optional","title":"Add a Domain (Optional)","text":"<p>If you want to use a domain instead of the IP address:</p>"},{"location":"docs/deployment/#add-a-subdomain","title":"Add a Subdomain","text":"<ol> <li>Go to your domain provider and open DNS settings of your domain.</li> <li>Add a new A Record:<ul> <li>Name: e.g., <code>dashboard</code> (let say for arkalos.com domain, this will be dashboard.arkalos.com)</li> <li>Value: your droplet\u2019s IP address</li> </ul> </li> <li>Add another A record:<ul> <li>Name: <code>www.dashboard</code></li> <li>Value: same IP address</li> </ul> </li> </ol>"},{"location":"docs/deployment/#point-a-full-domain-to-digitalocean","title":"Point a Full Domain to DigitalOcean","text":"<ol> <li>Or instead, in DigitalOcean, go to Networking &gt; Domains.</li> <li>Add your domain (e.g., <code>arkalos.com</code>).</li> <li>Create A records to point to the droplet:<ul> <li><code>@</code> \u2192 droplet IP</li> <li><code>www</code> \u2192 droplet IP</li> </ul> </li> <li>At your domain registrar, change nameservers to:</li> </ol> <pre><code>ns1.digitalocean.com\nns2.digitalocean.com\nns3.digitalocean.com\n</code></pre> <p>Note</p> <p>If you change nameservers and had DNS settings previously, be sure to reconfigure any email or website or other settings in DigitalOcean.</p>"},{"location":"docs/deployment/#create-a-new-user","title":"Create a New User","text":""},{"location":"docs/deployment/#connect-to-droplet-via-ssh","title":"Connect to Droplet via SSH","text":"<pre><code>ssh root@your-droplet-ip-or-domain\n</code></pre> <p>Approve the connection if prompted. Then update the system:</p> <pre><code>apt update &amp;&amp; apt upgrade -y\n</code></pre> <p>Choose to override config files with the maintainer's version if prompted.</p>"},{"location":"docs/deployment/#create-a-new-user_1","title":"Create a New User","text":"<pre><code>adduser arkalos-app # specify a desired username, e.g. arkalos-app\nusermod -aG sudo arkalos-app # add a user to sudo group\n</code></pre> <p>Switch to the new user:</p> <pre><code>su - arkalos-app\nexit  # Go back to root\nexit  # End SSH session\n</code></pre>"},{"location":"docs/deployment/#set-up-ssh-access-github-secrets","title":"Set Up SSH Access &amp; GitHub Secrets","text":""},{"location":"docs/deployment/#on-your-local-machine","title":"On Your Local Machine","text":"<pre><code># provide a comment in \"\", i.e. for what purpose is this key, and a file name at the end\nssh-keygen -t rsa -b 4096 -C \"do__arkalos-app__your@email.com\" -f ~/.ssh/do_arkalos_app_key\n</code></pre> <p>Copy the public key:</p> <pre><code>cat ~/.ssh/do_arkalos_app_key.pub\n</code></pre>"},{"location":"docs/deployment/#on-your-droplet","title":"On Your Droplet","text":"<pre><code>ssh root@your-droplet\nsu - arkalos-app\nmkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh\ntouch ~/.ssh/authorized_keys &amp;&amp; chmod 600 ~/.ssh/authorized_keys\nnano ~/.ssh/authorized_keys\n</code></pre> Droplet (New user): ~/.ssh/authorized_keys<pre><code># &lt;Your name&gt; &amp; GitHub action's key for DigitalOcean\npaste SSH public key here (right mouse click to paste)\n</code></pre> <p>Paste key into authorized_keys using nano editor. Save and exit with <code>Ctrl+X</code>, <code>Y</code>, <code>Enter</code>.</p> <p>Then update SSH config:</p> <pre><code>sudo nano /etc/ssh/sshd_config\n\n# Ensure these lines are uncommented:\nPubkeyAuthentication yes\nAuthorizedKeysFile .ssh/authorized_keys .ssh/authorized_keys2\n\n# Save with Ctrl+X, Y, Enter and restart the SSH service\nsudo systemctl restart ssh\n</code></pre>"},{"location":"docs/deployment/#add-github-repository-secrets","title":"Add GitHub Repository Secrets","text":"<p>Go to Settings &gt; Secrets and Variables &gt; Actions and add:</p> <ul> <li><code>DEPLOY_HOST</code>: your droplet IP or domain</li> <li><code>DEPLOY_USER</code>: arkalos-app or any Ubuntu username you specified</li> <li><code>DEPLOY_SSH_PRIVATE_KEY</code>: the content of your private key. Copy the output of <code>cat ~/.ssh/do_arkalos_app_key</code></li> <li><code>DEPLOY_APP_DIR</code>: e.g., <code>/home/arkalos-app/apps/arkalos-app</code></li> </ul>"},{"location":"docs/deployment/#edit-local-ssh-config","title":"Edit Local SSH Config","text":"Your Computer, not VPS<pre><code>nano ~/.ssh/config\n</code></pre> <pre><code>Host arkalos-app\n    HostName your-droplet-ip-or-domain\n    User arkalos-app\n    IdentityFile ~/.ssh/do_arkalos_app_key\n</code></pre> <p>Now test with:</p> <pre><code>ssh arkalos-app\n</code></pre> <p>If it works, disable root login.</p>"},{"location":"docs/deployment/#disable-root-login","title":"Disable Root Login","text":"<pre><code>sudo nano /etc/ssh/sshd_config\n\n# Change to no:\nPermitRootLogin no\n\n# Save the file with Ctrl+X, Y, Enter and Restart the SSH\nsudo systemctl restart ssh\n</code></pre> <p>Try logging in with root again \u2014 you should be denied.</p>"},{"location":"docs/deployment/#add-a-deploy-key-for-the-server","title":"Add a Deploy Key for the Server","text":"<p>On the Droplet, generate a key:</p> On the DigitalOcean:<pre><code>ssh-keygen -t ed25519 -f ~/.ssh/github_deploy_key -C \"deploy-key-arkalos-app\"\n</code></pre> <p>Copy the public key:</p> <pre><code>cat ~/.ssh/github_deploy_key.pub\n</code></pre> <p>On GitHub, go to Settings &gt; Deploy Keys, click Add Key, and paste it. Do not enable write access.</p>"},{"location":"docs/deployment/#update-servers-ssh-config","title":"Update Server's SSH Config","text":"On the DigitalOcean:<pre><code>nano ~/.ssh/config\n</code></pre> <pre><code>Host github.com\n    HostName github.com\n    User git\n    IdentityFile ~/.ssh/github_deploy_key\n    IdentitiesOnly yes\n</code></pre> <p>Test the connection:</p> <pre><code>ssh -T git@github.com\n</code></pre>"},{"location":"docs/deployment/#set-up-project-edit-env","title":"Set Up Project &amp; Edit .env","text":"<p>Create an application directory and clone the repository.</p> On the DigitalOcean:<pre><code>mkdir -p ~/apps/arkalos-app\ncd ~/apps/arkalos-app\n\n# copy the link from GitHub, and make sure there is . at the end\ngit clone git@github.com:your-username/your-repo.git . \n\ncp .env.example .env\n\nuv sync\n\ncd frontend\n\nnpm install\n\nnpm run build\n\ncd ..\n</code></pre> <p>Update <code>.env</code> with production credentials.</p>"},{"location":"docs/deployment/#install-uv-nodejs-and-pm2","title":"Install uv, NodeJS and PM2","text":"<p>Now, add final packages to the server.</p> <p>Install uv:</p> On the DigitalOcean:<pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> <p>Now you can check if uv is available by typing <code>uv -V</code>.</p> <p>Install NodeJS and npm:</p> <pre><code>curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash -\n\nsudo apt-get install -y nodejs\nsudo npm install -g npm@latest\n</code></pre> <p>Test with <code>node -v</code>; you shall see at least v22.14.0.</p> <p>Lastly, install PM2:</p> <p>PM2 is a simple, yet advanced, production process manager, that allows running scripts and apps on the background at all times and auto restart them.</p> <pre><code>sudo npm install pm2 -g\n\npm2 startup\n# this will output the command,\n# Copy and run it, it may look something like:\nsudo env PATH=$PATH:/usr/bin /usr/lib/node_modules/pm2/bin/pm2 startup systemd -u arkalos-app --hp /home/arkalos-app\n</code></pre> <p>If you wish to test pm2 locally first on your computer and you are using a WSL, you may need to wrap the PATH= command in quotes, e.g. sudo env \"PATH=$PATH:/usr/bin\" ...</p> <p>Test PM2 is running:</p> <p>Check status with <code>pm2 status</code>.</p> <p>Check the details of the process with <code>pm2 info arkalos-app</code></p> <p>Check the logs with <code>pm2 logs</code> or inside the new user's home direcotry ~/.pm2/logs.</p> <p>If it looks good, save the process and enable it on startup, for example, when server is restarting, with <code>pm2 save</code>.</p>"},{"location":"docs/deployment/#configure-nginx-ssl","title":"Configure Nginx &amp; SSL","text":"On the DigitalOcean:<pre><code>sudo apt install nginx certbot python3-certbot-nginx -y\n</code></pre> <p>Create a new website Nginx config file. If using a domain, Arkalos includes pre-configured files in <code>.devops/nginx/sites-available/</code> that you could copy.</p> Create a new site config file:<pre><code># sudo nano /etc/nginx/sites-available/&lt;site name&gt;, i.e.:\nsudo nano /etc/nginx/sites-available/arkalos_app.conf\n\n# or with a custom domain, specify your own domain\nsudo nano /etc/nginx/sites-available/dashboard.arkalos.com.conf\n</code></pre> <p>Example config for IP-only:</p> <p>If you have a domain, check the config example below.</p> Without domain: /etc/nginx/sites-available/example.com.conf<pre><code>server {\n    listen 80;\n    server_name YOUR_DROPLET_IP;\n\n    location / {\n        proxy_pass http://127.0.0.1:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre> <p>Then:</p> <pre><code># Create a symbolic link to enable the website config\nsudo ln -s /etc/nginx/sites-available/example.com.conf /etc/nginx/sites-enabled/\n\n# Disable the default site\nsudo rm /etc/nginx/sites-enabled/default\n\n# Test config\nsudo nginx -t\n\n# If it's good, reload the service\nsudo service nginx reload\n</code></pre>"},{"location":"docs/deployment/#for-ssl-https-and-http2","title":"For SSL, HTTPS and HTTP2:","text":"<p>This will require a domain.</p> <p>Generate a new SSL certificate for your domain. SPecify your domain with and without www:</p> DigitalOcean:<pre><code>sudo certbot --nginx -d yourdomain.com -d www.yourdomain.com\n</code></pre> <p>Provide your email when asked.</p> <p>Answer Y to the terms.</p> <p>Answer Y or N if you wish to receive email updates.</p> <p>Then you shall see \"successfully deployed certificate\" and your example.com nginx config file will be updated.</p> <p>To verify auto-renewal is enabled:</p> <pre><code>sudo systemctl status certbot.timer\n</code></pre>"},{"location":"docs/deployment/#nginx-site-confing-for-ssl","title":"Nginx site confing for SSL:","text":"<p>Note</p> <p>If using domains and SSL, Arkalos projects come with the <code>.devops</code> folder and a pre-configured site example file.</p> <ol> <li>Rename the <code>.devops/nginx/sites-available/example.com.conf</code> file to match the desired file name with your domain or app name.</li> <li>Edit the file and replace <code>example.com</code> with your domain everywhere. In the VS Code, press Ctrl+F, search for example.com, then press the \"&gt;\" arrow on the left and a new line will appear, type your domain into replace box, and click the last Replace All button to the right.</li> <li>The file looks as such: /etc/nginx/sites-available/example.com.conf (With SSL, HTTP2 &amp; Redirects)<pre><code># /etc/nginx/sites-available/example.com.conf\n\n# Replace example.com everywhere with your domain\n\n# Redirect all HTTP traffic to HTTPS\nserver {\n    listen 80;\n    listen [::]:80;\n    server_name example.com www.example.com;\n    return 301 https://example.com$request_uri;\n}\n\n# Redirect www to non-www over HTTPS\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name www.example.com;\n    return 301 https://example.com$request_uri;\n\n    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n}\n\n# Main server block for non-www\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n    server_name example.com;\n\n    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\n    include /etc/letsencrypt/options-ssl-nginx.conf;\n    ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem;\n\n    location / {\n        proxy_pass http://127.0.0.1:8000;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre></li> <li>After you updated the file in your project, make sure to git push, and then you can simply copy this file on your server. From your app directory: <pre><code>cd ~/apps/arkalos-app\nsudo cp .devops/nginx/sites-available/domain.com.conf /etc/nginx/sites-available/domain.com.conf\n</code></pre></li> <li>Make sure there is a symbolic link: <pre><code>sudo ln -s /etc/nginx/sites-available/domain.com.conf /etc/nginx/sites-enabled/\n</code></pre></li> </ol>"},{"location":"docs/deployment/#final-notes","title":"Final notes","text":"<p>Arkalos Python projects include pre-configured configs:</p> <ul> <li><code>.github/workflows/deploy.yml</code>: Automatically runs GitHub deployment action on push to main.</li> <li><code>.devops/nginx/...</code>: Ready-to-use Nginx configs.</li> <li><code>ecosystem.config.js</code>: PM2 config. Update <code>name</code> if needed, and reflect it in <code>deploy.yml</code>.</li> </ul> <p>Once this setup is complete, you can deploy by simply pushing to git.</p>"},{"location":"docs/domains/","title":"Python FastAPI Domains, Models &amp; Controllers","text":"<p>Multitier software architecture and design patterns help us write simple, maintainable, testable, and easily adjustable and scalable code.</p> <p>Arkalos provides a default structure for various tiers of your architecture that are similar across different types of software.</p> <p>However, the business logic or any use-case-specific and domain knowledge is unique to every project. Arkalos doesn't dictate where you should create your models, domains, or controllers, or even if you need them.</p> <p>That said, Arkalos includes an example domain class in <code>app/domains/example/example.py</code>, which uses the <code>vega_datasets</code> library to generate some example charts for the initial dashboard. You can delete or adjust this as you see fit.</p>"},{"location":"docs/domains/#where-to-put-business-logic","title":"Where to Put Business Logic?","text":"<p>If your application is small, you may use or create directories such as <code>app/models</code>, <code>app/data/types</code>, <code>app/http/actions</code>, and <code>app/http/controllers</code> to house your models and business-specific code. Then, import and use them from your routes.</p> <p>If you plan to have multiple use-cases, more sections and domains of knowledge, or better organize your codebase\u2014where all the models, data types, actions or controllers, and other code related to a particular domain live inside the same directory like an independent sub-project\u2014then you may stick to the <code>app/domains</code> folder.</p>"},{"location":"docs/domains/#about-domain-driven-design","title":"About Domain-Driven Design","text":"<p>Domain-Driven Design (DDD) is a standard approach in professional application design that helps us understand the particular knowledge domain and its boundaries, and better structure our code to meet the always-changing requirements.</p> <p>Each domain will have its own directory, and then each directory will have a similar structure. For instance, each domain might have some of these folders:</p> <ul> <li><code>app/domains/{domain}/</code></li> <li><code>app/domains/{domain}/actions/</code></li> <li><code>app/domains/{domain}/models/</code></li> <li><code>app/domains/{domain}/types/</code></li> </ul> <p>Each domain must be treated as an absolutely independent project. Only the domain itself knows about its structure and internals. Other domains should never access deeper internal parts of other domains, but instead access it only via the entry point\u2014like the main gates to a palace\u2014and then the domain itself provides what is requested. Think of it as object-oriented programming (OOP) but at a larger scale, where entire folders and files are like private methods.</p> <p>Note</p> <p>This entry point is often known as an Aggregate Root, and usually takes the form of a class with the same name as the domain and folder name. <code>app/domains/example/example.py</code> is an example of that root.</p> <p>Designing domains and naming our folders, files, and entities requires at least a basic understanding of the domain and close collaboration with domain experts. This helps the entire team and organization to align, enabling both technical and non-technical people to speak the same language.</p> <p>This also helps to decouple your architecture and, if needed in the future, to easily separate your codebase into multiple repositories and microservices.</p>"},{"location":"docs/domains/#understanding-data-models-data-types-and-ai-models","title":"Understanding Data Models, Data Types, and AI Models","text":""},{"location":"docs/domains/#what-is-a-data-model","title":"What is a Data Model?","text":"<p>A data model is a conceptual representation or structure that defines how data is organized, stored, and manipulated within a system or application. It specifies the relationships between different data entities, the attributes of those entities, and the rules governing the data.</p> <p>In the context of Arkalos, a data model represents business data and can take various forms:</p> <ul> <li>A custom class</li> <li>A table in the database</li> <li>A simple static model or dictionary (e.g., a list of US states)</li> </ul> <p>It serves as the interface between the application and domain language and the raw data storage. For example, we might have a <code>User</code> model with a corresponding <code>user</code> table in the database and a <code>UserType</code> data type. We could easily add a new user with a <code>User.create()</code> method or fetch only admin users with <code>User.admins()</code>.</p> <p>This abstraction allows us to replace the underlying data storage without rewriting our entire codebase.</p>"},{"location":"docs/domains/#what-is-a-data-type","title":"What is a Data Type?","text":"<p>A data type or data transfer object (DTO) is a custom data structure for a particular model, request, or any use case. It defines the shape and type of data being handled, ensuring consistency and validation across the application.</p> <p>For example, using Python's <code>dataclasses</code> or Pydantic's <code>BaseModel</code>, we can define data types that validate incoming data and provide clear documentation for the expected structure.</p>"},{"location":"docs/domains/#what-is-an-ai-model","title":"What is an AI Model?","text":"<p>An AI model is a computational representation of a real-world process or problem that can be learned from data. AI models are created using machine learning algorithms and techniques to analyze and learn patterns from training data. These models are then used to make predictions or decisions on new, unseen data.</p> <p>Examples of AI models include:</p> <ul> <li>Linear regression</li> <li>Decision trees</li> <li>Support vector machines</li> <li>Neural networks</li> </ul> <p>In Arkalos, AI models can be integrated into your domains to provide intelligent features, such as recommendations, predictions, or classifications.</p> <p>This guide focuses only on the data models and types.</p>"},{"location":"docs/domains/#about-data-warehouses-data-products-olap-and-oltp","title":"About Data Warehouses, Data Products, OLAP, and OLTP","text":"<p>When building data products\u2014such as pipelines, analytics, reporting, automations, business intelligence (BI) tools, smart and AI engines, dashboards, and data warehouses\u2014it's important to separate the core business domain and requirements from the design of the data structure and flows that are independent from the business operations.</p>"},{"location":"docs/domains/#oltp-online-transaction-processing","title":"OLTP (Online Transaction Processing)","text":"<p>In typical products and small applications, you usually design a single database and focus on transactional data, known as OLTP. OLTP systems are optimized for managing current day-to-day data information, handling large numbers of short online transactions (INSERT, UPDATE, DELETE). They emphasize fast query processing and maintaining data integrity in multi-access environments.</p>"},{"location":"docs/domains/#olap-online-analytical-processing","title":"OLAP (Online Analytical Processing)","text":"<p>When designing data products, data warehouses, and the entire infrastructure, the approach is different and is known as OLAP. OLAP systems are designed for complex queries and data analysis, enabling businesses to derive insights from vast datasets through multidimensional analysis.</p> <p>For example, in OLTP and your main database, you care less about historical data and logs, and store all kinds of information in a normalized way. This, however, might not be the optimal approach when it comes to reading historical data.</p>"},{"location":"docs/domains/#data-warehouse","title":"Data Warehouse","text":"<p>A data warehouse is a kind of database that:</p> <ul> <li>Connects multiple data sources, such as your main OLTP product database, CRM, project management tools, social media analytics, and so on.</li> <li>Provides historical data.</li> </ul> <p>Data warehouses and data pipelines often access various data sources via polling. For example, your main product and database is a task management tool, and there is a <code>tasks</code> table with a <code>status</code> column. But anytime the status is changed, you have no historical record of that.</p> <p>A data warehouse could access this table every hour to retrieve the new and updated data and store changes in the data itself over time.</p> <p>Historical data is a cornerstone of analytics and data-driven business decisions and intelligence.</p> <p>There are two common classical ways of designing a data warehouse:</p> <ul> <li>Inmon approach: Focuses on building a centralized data warehouse first, then creating data marts for specific business areas.</li> <li>Kimball approach: Emphasizes building data marts first, which are then integrated into a data warehouse.</li> </ul>"},{"location":"docs/domains/#what-is-a-controller-and-action","title":"What is a Controller and Action?","text":"<p>An action is an atomic unit of operation that a domain or the project can perform and exposes these actions to the user.</p> <p>Domains can have domain actions.</p> <p>A controller is a general term and refers to any part of the code responsible for controlling and connecting different pieces of code together. For example, AI agents are controllers, HTTP routes are controllers.</p> <p>Controllers are useful when you need to group many actions and routes together. Even if we have multiple route files in the <code>app/http/routes</code> directory, when a particular page or domain grows, we don't want our route functions to become too large. Instead, we can delegate this to a controller or an action.</p> <p>Controllers are often used in simple MVC-type applications. With domains, it's recommended to use domain actions instead because the aggregate root is our controller.</p>"},{"location":"docs/domains/#creating-a-domain","title":"Creating a Domain","text":"<p>Let's refactor our previous example from the Routes guide about the Reports.</p> <p>Create <code>app/domains/report/</code> folder.</p>"},{"location":"docs/domains/#data-types","title":"Data Types","text":"<p>Now let's create a new <code>app/domains/report/types/</code> folder and new files and data types:</p> app/domains/report/types/car_origin_type.py<pre><code>from enum import StrEnum\n\nclass CarOriginType(StrEnum):\n    US = 'usa'\n    JAPAN = 'japan'\n    EU = 'europe'\n</code></pre> app/domains/report/types/car_report_type.py<pre><code>import datetime\nfrom pydantic import BaseModel, model_validator\n\nfrom app.domains.report.types.car_origin_type import CarOriginType\n\nclass CarReportType(BaseModel):\n    Name: str\n    Miles_per_Gallon: float\n    Cylinders: int\n    Displacement: float\n    Horsepower: float\n    Weight_in_lbs: int\n    Acceleration: float\n    Year: datetime.date\n    Origin: CarOriginType\n\n    @model_validator(mode='after')\n    def check_mph_cylinders_ratio(self) -&gt; 'CarReportType':\n        '''As the cylinder count increases, average MPG usually decreases'''\n        mpg = self.Miles_per_Gallon\n        cylinders = self.Cylinders\n        if mpg &gt; 50 and cylinders &gt; 6:\n            raise ValueError(\"High MPG with many cylinders is suspicious\")\n        return self\n</code></pre> <p>We then in our code could use this class to easily create a new data or validate it:</p> notebooks/car_report.ipynb<pre><code>new_cars = [\n    CarReportType(\n        Name=\"Pydantic Test Car 1\",\n        Miles_per_Gallon=30.5,\n        Cylinders=4,\n        Displacement=140.0,\n        Horsepower=90.0,\n        Weight_in_lbs=2500,\n        Acceleration=15.0,\n        Year=datetime.date(2025, 1, 1),\n        Origin=OriginType.JAPAN\n    ),\n    CarReportType(\n        Name=\"Pydantic Test Car 2\",\n        Miles_per_Gallon=22.0, # Set this to &gt; 50\n        Cylinders=6, # and this to &gt; 6 to test our custom data analysis validation\n        Displacement=200.0,\n        Horsepower=110.0,\n        Weight_in_lbs=3000,\n        Acceleration=12.5,\n        Year=datetime.date(2025, 1, 1),\n        Origin=OriginType.US\n    )\n]\n\nreport = CarReport(new_cars)\nreport.filterByOrigin(OriginType.US)\ndf = report.getPolarsDf()\ndf\n</code></pre> <p>Note</p> <p>Data types help us see which exact columns, column names, data and types we are dealing with. It helps with alignment and communication, and also acts as a documentation and a certain safety check or custom validators for data analysis that could warn us if something looks suspicious, or if something is just missing or not valid.</p>"},{"location":"docs/domains/#data-models","title":"Data Models","text":"<p>Now let's create the main data model. In a real scenario we would have to design a DB or new data structure to store our data, but we will continue in this example with the vega_datasets.</p> <p>Create <code>app/domains/report/models/</code> folder and <code>app/domains/report/models/car_report.py</code> model</p> app/domains/report/models/car_report.py<pre><code>from vega_datasets import data as datasets # type: ignore\nimport polars as pl\n\nfrom app.domains.report.types.car_report_type import CarReportType\n\nclass CarReport:\n\n    df: pl.DataFrame\n\n    def __init__(self, data: list[CarReportType]|None = None):\n        if data:\n            self.df = pl.DataFrame(data)\n        else:\n            cars_df = datasets.cars()\n            self.df = pl.from_pandas(cars_df)\n\n    def getPolarsDf(self) -&gt; pl.DataFrame:\n        return self.df\n\n    def isEmpty(self) -&gt; bool:\n        return self.df.is_empty()\n\n    def filterByOrigin(self, origin: str|None = None):\n        if origin:\n            self.df = self.df.filter(pl.col(\"Origin\").str.to_lowercase() == origin.lower())\n\n    def getJSON(self) -&gt; str:\n        return self.df.write_json()\n</code></pre>"},{"location":"docs/domains/#domain-actions","title":"Domain Actions","text":"<p>Now let's create domain actions that we want to expose outiside of this domain, i.e. to our HTTP routes and the user.</p> <p>Create a new <code>app/domains/report/actions/</code> folder and <code>get_car_report_action.py</code> file inside:</p> app/domains/report/actions/get_car_report_action.py<pre><code>from app.domains.report.types.car_origin_type import CarOriginType\nfrom app.domains.report.models.car_report import CarReport\n\nclass GetCarReportAction:\n\n    def __call__(self, origin: CarOriginType|None = None) -&gt; str|bool:\n        '''Return report as JSON data or False if no records found for car origin type'''\n        report = CarReport()\n        report.filterByOrigin(origin)\n        if report.isEmpty():\n            return False\n        return report.getJSON()\n</code></pre>"},{"location":"docs/domains/#domain-aggregate-root","title":"Domain Aggregate Root","text":"<p>Finally, let's create the main aggregate and domain entry class <code>app/domains/report/report.py</code></p> app/domains/report/report.py<pre><code>from app.domains.report.types.car_origin_type import CarOriginType\nfrom app.domains.report.actions.get_car_report_action import GetCarReportAction\n\nclass Report:\n\n    def getCarReport(self, origin: CarOriginType|None = None) -&gt; str|bool:\n        '''Return report as JSON data or False if no records found for car origin type'''\n        action = GetCarReportAction()\n        return action(origin)\n</code></pre> <p>And we can now use it in our <code>app/http/routes/report.py</code> route and refactor it:</p> <p>Using search query params:</p> app/http/routes/reports.py<pre><code>from arkalos import router\n\nfrom app.domains.report.report import Report\nfrom app.domains.report.types.car_origin_type import CarOriginType\n\n@router.get('/reports')\nasync def reports(origin: CarOriginType|None = None):\n    domain = Report()\n    data = domain.getCarReport(origin)\n\n    if not data:\n        return []\n\n    return data\n</code></pre> <p>Or using path params:</p> app/http/routes/reports.py<pre><code>from arkalos import router\nfrom arkalos.http import response\n\nfrom app.domains.report.report import Report\n\n\n\n@router.get('/reports')\nasync def reports():\n    domain = Report()\n    return domain.getCarReport()\n\n@router.get('/reports/{origin}')\nasync def reports_category(origin: str):\n    domain = Report()\n    data = domain.getCarReport(origin)\n\n    if not data:\n        return response('Category not found', 404)\n\n    return data\n</code></pre> <p>And it all is now much cleaner, better organized and we can scale this easily and our routes look clean and short. We adhere to the principle of single responsibility.</p>"},{"location":"docs/fetch/","title":"Fetching API Data in React Router Pages From Python FastAPI Endpoints","text":"<p>Once your FastAPI backend endpoints are set up, you can fetch and display that data inside your frontend pages using Arkalos components and hooks.</p>"},{"location":"docs/fetch/#using-the-dataloader-component","title":"Using the <code>&lt;DataLoader&gt;</code> Component","text":"<p>The <code>&lt;DataLoader&gt;</code> component simplifies data fetching during initial page rendering. It automatically handles loading states, error handling, and animations.</p>"},{"location":"docs/fetch/#steps-to-use-dataloader","title":"Steps to Use <code>&lt;DataLoader&gt;</code>:","text":"<ol> <li>Create a local function like <code>render(data)</code> that will receive and render the fetched data.</li> <li>Specify the backend API endpoint URL (no need to prefix it with <code>/api</code>\u2014it's added automatically).</li> <li>Pass the <code>render</code> function to the <code>fn</code> prop of <code>&lt;DataLoader&gt;</code>.</li> <li>Optionally, pass query parameters or payload data via the <code>data</code> prop.</li> </ol>"},{"location":"docs/fetch/#example-basic-data-fetch","title":"Example: Basic Data Fetch","text":"<p>Assume your backend provides data from <code>/api/reports</code>. Here's how to fetch and render that in the About page:</p> frontend/app/pages/AboutPage.jsx<pre><code>import MainLayout from '@/layouts/MainLayout'\nimport DataLoader from '@/components/DataLoader'\n\nexport default function AboutPage() {\n\n  function render(data) {\n    console.log('Data fetched: ', data)\n    return (\n      &lt;ul&gt;\n        {data.map((item, idx) =&gt; (\n          &lt;li key={idx}&gt;{item.title}&lt;/li&gt;\n        ))}\n      &lt;/ul&gt;\n    )\n  }\n\n  return (\n    &lt;MainLayout title=\"About\"&gt;\n      &lt;h1&gt;About Page&lt;/h1&gt;\n      &lt;section&gt;\n        &lt;DataLoader url=\"/reports\" fn={render} /&gt;\n      &lt;/section&gt;\n    &lt;/MainLayout&gt;\n  )\n}\n</code></pre>"},{"location":"docs/fetch/#example-fetching-filtered-data","title":"Example: Fetching Filtered Data","text":"<p>To pass query parameters (e.g. <code>/api/reports?origin=japan</code>):</p> <pre><code>&lt;DataLoader url=\"/reports\" data={{ origin: 'japan' }} fn={render} /&gt;\n</code></pre>"},{"location":"docs/fetch/#using-the-usefetchapi-hook","title":"Using the \"useFetchApi\" Hook","text":"<p><code>&lt;DataLoader&gt;</code> is powered by a custom <code>useFetchApi</code> hook that you can use directly for more control.</p> <pre><code>import { useFetchApi } from '@/hooks/useFetchApi'\n\n// Inside your component:\nconst [data, error, isLoading] = useFetchApi.get('/reports', { origin: 'japan' })\n</code></pre> <p>This gives you fine-grained access to the loading and error states.</p>"},{"location":"docs/fetch/#using-the-api-service-for-manual-calls-post-formdata","title":"Using the \"Api\" Service for Manual Calls &amp; POST FormData","text":"<p>If you prefer fully manual control (e.g. inside event handlers or <code>useEffect</code>), you can use the <code>Api</code> service directly.</p> <pre><code>import Api from '@/services/Api'\n\n// Example: GET request\nconst [data, error] = Api.get('/reports')\n\n// Example: POST request with FormData\nasync function handleFormSubmit(form) {\n  const formData = new FormData(form)\n  const [data, error] = await Api.post('/something/create', formData)\n\n  if (error) {\n    console.error('API Error:', error)\n  } else {\n    console.log('Response:', data)\n  }\n}\n</code></pre>"},{"location":"docs/installation/","title":"Python Project Installation","text":"<p>Note</p> <p>Arkalos is in Beta, where the code may change or break without notice. Not all documentation and modules are complete. Use it only for experimentation, study, and practice, not for production use. Follow us and join the community to stay updated.</p>"},{"location":"docs/installation/#requirements","title":"Requirements","text":"<ul> <li>Git</li> <li>Python &gt; 3.13</li> <li>Python <code>uv</code> package manager &gt; 0.5.29</li> <li>Ollama - for downloading, running, and building LLMs locally.</li> <li>IDE - like VS Code</li> <li>Just basic coding skills. You don't have to know math, stats, ML/AI to use core Arkalos features.</li> </ul>"},{"location":"docs/installation/#for-windows-users","title":"For Windows Users","text":"<p>If you're on Windows, we recommend using Windows Subsystem for Linux (WSL).</p> <p>Check out Microsoft's installation guide.</p>"},{"location":"docs/installation/#git","title":"Git","text":"<p>You likely have Git installed already.</p> <p>If not, follow GitHub's Installing Git guide.</p> <p>To verify installation:</p> <pre><code>git --version\n</code></pre>"},{"location":"docs/installation/#uv-package-manager","title":"UV Package Manager","text":"<p><code>uv</code> is a modern, super-fast Python package and project manager.</p> <p>If you've used NodeJS (npm) or PHP (Composer), it's similar.</p> <ul> <li><code>pyproject.toml</code> is like <code>package.json</code>.</li> <li>Use commands like <code>uv add &lt;package&gt;</code> or <code>uv sync</code> to manage dependencies.</li> </ul> <p>To install <code>uv</code>:</p> Mac, WSL, and LinuxWindows <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> <pre><code>powershell -ExecutionPolicy ByPass -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre> <p>For more details, see the uv documentation.</p> <p>To verify installation:</p> <pre><code>uv -V\n</code></pre>"},{"location":"docs/installation/#python","title":"Python","text":"<p>Download and install the latest Python version from the official site.</p> <p>Alternatively, use <code>uv</code> to install Python:</p> <pre><code>uv python install\n</code></pre> <p>To verify installation:</p> <pre><code>python -V\n</code></pre>"},{"location":"docs/installation/#installing-ollama-and-open-source-ai-models","title":"Installing Ollama and Open-Source AI Models","text":"<p>Ollama is a sleek, user-friendly app, CLI, framework, and repository for managing open-source LLMs locally.</p> <p>Download and install Ollama.</p> <p>To verify installation:</p> <pre><code>ollama -v\n</code></pre> <p>For more details, CLI commands, and RAM requirements, visit the Ollama GitHub repository.</p> <p>Once installed, open a new terminal and start the Ollama server:</p> <pre><code>ollama serve\n</code></pre> <p>Now, you can download various open-source LLMs like DeepSeek, Llama, Mistral, and Gemma.</p> <p>Open a new terminal and download your preferred model. Smaller models (~5GB) will take some time.</p> <p>You'll need at least 8GB of RAM for 7B models.</p> <p>Arkalos includes a basic AI Agent \u2014 a terminal chatbot to interact with your data warehouse.</p> <p>We recommend downloading the qwen-2.5-coder model (7B by default) while continuing with this guide:</p> <pre><code>ollama pull qwen2.5-coder\n</code></pre>"},{"location":"docs/installation/#recommended-vs-code-settings-and-extensions-for-python-data-ai-projects","title":"Recommended VS Code Settings and Extensions for Python Data &amp; AI Projects","text":"<p>We suggest using VS Code as your IDE because:</p> <ul> <li>It supports Jupyter Notebooks and other extensions.</li> <li>It includes a copilot.</li> <li>For Windows and WSL users, it simplifies working inside WSL.</li> </ul> <p>Download and install VS Code.</p>"},{"location":"docs/installation/#install-extensions","title":"Install Extensions:","text":"<p>From the Extensions side tab, search for and install:</p> <p>Official Microsoft Extensions:</p> <ul> <li>Python</li> <li>Python Debugger</li> <li>Pylance</li> <li>Data Wrangler</li> <li>Mypy Type Checker</li> <li>isort</li> <li>Jupyter (and extension packs)</li> <li>WSL (for Windows + WSL users)</li> </ul> <p>Other Recommended Extensions:</p> <ul> <li>Project Manager (by Alessandro Fragnani)</li> <li>DotENV (by mikestead)</li> <li>vscode-pdf (by tomoki1207)</li> <li>SQLite Viewer (by Florian Klampfer)</li> <li>Excel Viewer (by MESCIUS)</li> <li>Material Icon Theme (for a nicer look) (by Philipp Kief)</li> </ul>"},{"location":"docs/installation/#create-a-new-arkalos-project","title":"Create a New Arkalos Project","text":"<p>You're all set! Now, you can create a new Arkalos project.</p>"},{"location":"docs/logs/","title":"Python Logs and Debugging","text":""},{"location":"docs/logs/#debugging","title":"Debugging","text":"<p>To identify issues in your code, start by adding <code>print()</code>, <code>var_dump()</code>, or <code>dd()</code> functions. These help inspect variable values and data types during execution.</p> <p>When you are dealing with errors and exceptions, you can also wrap your code in <code>try - except</code> block.</p> <p>Instead of manually commenting out large sections of code, use the <code>dd()</code> function to halt execution at a specific point:</p> <pre><code>from arkalos import dd\n\ndef calculate_square(x):\n    result = x * x\n    dd(result)  # This will print the result and stop the script\n    return result\n\ndef main():\n    number = 5\n    square = calculate_square(number)\n    # The following line won't run due to dd()\n    print(f\"The square of {number} is {square}\")\n\nmain()\n</code></pre>"},{"location":"docs/logs/#logging","title":"Logging","text":"<p>Arkalos includes a pre-configured file-based logger for easy tracking of events:</p> <pre><code>from arkalos import Log\n\nLog.debug('debug message')\nLog.info('info message')\nLog.warning('warning message')\nLog.error('error message')\nLog.critical('critical error')\n</code></pre> <p>This will generate a log file in <code>data/logs/arkalos-&lt;year&gt;-&lt;month&gt;.log</code>.</p> <p>You can open it in VS Code to check the details, including the exact date and time in UTC (Zulu) timezone.</p>"},{"location":"docs/logs/#logging-data","title":"Logging Data","text":"<p>To log additional data, pass it as a second argument:</p> <pre><code>from arkalos import Log\n\ndata = {\n    'id': 1,\n    'tags': ['one', 'two'],\n}\n\nLog.info('info message', data)\n</code></pre> <p>Logging allows you to review execution details in a log file, making it easier to debug issues.</p>"},{"location":"docs/logs/#what-next","title":"What Next","text":"<p>Now you can learn about the Registry &amp; Bootstrapping.</p>"},{"location":"docs/middleware/","title":"Python FastAPI Middleware Class","text":"<p>Middleware is like a security guard at the entrance to a mall. Most of the time, they simply observe people coming and going. But sometimes, like at airports, they inspect everyone passing through.</p> <p>HTTP middleware works similarly \u2014 it wraps around every request and response cycle. Middleware can run logic:</p> <ul> <li>Before the request is processed,</li> <li>After the response is generated,</li> <li>Or both before and after.</li> </ul> <p>Middleware is typically used for global services such as:</p> <ul> <li>Error handling</li> <li>Logging</li> <li>Authentication</li> </ul> <p>Each middleware should live in its own class and focus on a single concern. This makes debugging easier and allows enabling or disabling middleware with minimal impact.</p>"},{"location":"docs/middleware/#creating-a-new-middleware","title":"Creating a New Middleware","text":"<p>In Arkalos, to add a new middleware, create a file in the <code>app/http/middleware/</code> folder and extend the base <code>Middleware</code> class:</p> app/http/middleware/my_logs_middleware.py<pre><code>from typing import Callable\nfrom arkalos.http import Middleware, Request, Response\n\nclass MyLogsMiddleware(Middleware):\n\n    async def __call__(self, request: Request, call_next: Callable) -&gt; Response:\n        # BEFORE: The request is available, but no response yet\n        print(request.url.path)\n\n        # Pass control to the next middleware or the route handler\n        resp = await call_next(request)\n\n        # AFTER: Response is available, can log status or modify it\n        return resp\n</code></pre> <p>To create custom middleware, your class must:</p> <ul> <li>Inherit from <code>Middleware</code></li> <li>Implement the <code>async __call__(self, request, call_next)</code> method</li> <li>Call <code>await call_next(request)</code> to continue the chain</li> <li>Return the final response</li> </ul> <p>The example above prints the path of every request to the terminal.</p>"},{"location":"docs/middleware/#registering-middleware","title":"Registering Middleware","text":"<p>To enable your middleware, register it inside <code>app/bootstrap.py</code>:</p> app/bootstrap.py<pre><code># ...\n\nfrom app.http.middleware.my_logs_middleware import MyLogsMiddleware\n\n# ...\n\ndef run():\n    # ...\n\n    app = (HTTP()\n        .withBasePath(base_path())\n        .withMiddleware([\n            HandleExceptionsMiddleware,\n            LogRequestsMiddleware,\n            MyLogsMiddleware,  # \ud83d\udc48 Add your new middleware here\n        ])\n        .withRoutes([\n            ('app/http/routes', '/api')\n        ])\n        .withMountFrontendBuildDir()\n        .create()\n    )\n</code></pre> <p>Middleware runs in the order they are listed. That means your middleware will see the request after the ones listed above it, and process the response before them.</p>"},{"location":"docs/migrations/","title":"Python DB &amp; Data Warehouse Migrations","text":"<p>Arkalos lets you manage schema changes in your relational database or data warehouse with simple, versioned Python migration scripts. Built on top of SQLGlot and Ibis, Arkalos supports <code>CREATE TABLE</code>, <code>ALTER TABLE</code>, and other SQL operations using a Pythonic syntax.</p> <p>This guide shows how to write, organize, and run database and data warehouse migrations in your FastAPI or data engineering project using Arkalos.</p>"},{"location":"docs/migrations/#versioning-migrations","title":"Versioning Migrations","text":"<p>Arkalos organizes migrations by version subfolders, instead of storing many files in a single flat directory. This helps your team track schema changes logically alongside your app or warehouse version.</p> <p>Choose a versioning strategy and stick to it:</p> <ul> <li>Semantic versioning: <code>0.1.0</code>, <code>0.2.0</code>, etc.</li> <li>Minimal versioning: <code>0.1</code>, <code>0.2</code></li> <li>Date-based: <code>2025.06</code> for monthly migrations</li> <li>Year-based: <code>2025</code></li> </ul> <p>Example path:</p> <pre><code>app/schema/migrations/db/0.1.0/v20250604125127_create_users_table.py\n</code></pre>"},{"location":"docs/migrations/#creating-a-database-migration","title":"Creating a Database Migration","text":"<p>To generate a new database migration file:</p> <pre><code># uv run arkalos make:mig {version}/{table_name}\n\nuv run arkalos make:mig 0.1.0/users\n</code></pre> <p>This creates a migration template at <code>app/schema/migrations/db/...</code>:</p> <pre><code>from arkalos import DB\nfrom arkalos.schema.database_migration import DatabaseMigration\n\nclass Migration(DatabaseMigration):\n\n    def up(self):\n        with DB().createTable('users') as table:\n            table.col('id').id()\n            table.col('created_at').datetime().notNull().defaultNow()\n            table.col('updated_at').datetime().notNull().defaultNow()\n\n    def down(self):\n        DB().dropTable('users')\n</code></pre> <p>If you create migrations manually, name the file starting with <code>v</code> and use underscores: <code>_</code>.</p>"},{"location":"docs/migrations/#creating-a-data-warehouse-migration","title":"Creating a Data Warehouse Migration","text":"<p>To create a data warehouse migration:</p> <pre><code>uv run arkalos make:mig:dwh 0.1.0/users\n</code></pre> <p>This generates a file in:</p> <pre><code>app/schema/migrations/dwh/...\n</code></pre> <p>Example migration:</p> <pre><code>from arkalos import DWH\nfrom arkalos.schema.data_warehouse_migration import DataWarehouseMigration\n\nclass Migration(DataWarehouseMigration):\n\n    def up(self):\n        with DWH().clean().createTable('users') as table:\n            table.col('id').id()\n            table.col('created_at').datetime().notNull().defaultNow()\n            table.col('updated_at').datetime().notNull().defaultNow()\n\n    def down(self):\n        DWH().clean().dropTable('users')\n</code></pre>"},{"location":"docs/migrations/#data-warehouse-layers","title":"Data Warehouse Layers","text":"<p>Most data warehouses follow a three-layer architecture:</p> <ul> <li><code>raw</code> (bronze): lightly structured ingestion layer</li> <li><code>clean</code> (silver): normalized, validated data</li> <li><code>BI</code> (gold): business-ready reporting tables</li> </ul> <p>You can target these layers using the appropriate facade:</p> <pre><code>DWH().raw().createTable('...')\nDWH().clean().createTable('...')\nDWH().BI().createTable('...')\n</code></pre>"},{"location":"docs/migrations/#running-and-rolling-back-migrations","title":"Running and Rolling Back Migrations","text":"<p>Run all database migrations:</p> <pre><code>uv run arkalos migrate\n</code></pre> <p>Run only a specific version:</p> <pre><code>uv run arkalos migrate 0.1.0\n</code></pre> <p>Rollback the last database migration:</p> <pre><code>uv run arkalos rollback\n</code></pre> <p>Run all data warehouse migrations:</p> <pre><code>uv run arkalos migrate:dwh\n</code></pre> <p>Rollback data warehouse migrations:</p> <pre><code>uv run arkalos rollback:dwh\n</code></pre>"},{"location":"docs/migrations/#alter-tables-with-sqlglot-and-ibis","title":"Alter Tables with SQLGlot and Ibis","text":"<p>To alter a table instead of creating it, use <code>alterTable()</code>:</p> <pre><code>with DWH().clean().alterTable('users') as table:\n    table.col('new_col').text()\n</code></pre>"},{"location":"docs/migrations/#table-syntax-and-column-types","title":"Table Syntax and Column Types","text":"<p>Start by creating or altering a table with:</p> <pre><code>with DWH().clean().createTable('users') as table:\n    table.col('id').id()\n</code></pre>"},{"location":"docs/migrations/#column-types","title":"Column Types","text":"<p>Integer:</p> <ul> <li><code>.id()</code> \u2013 Primary key, auto-increment bigint</li> <li><code>.integer()</code> / <code>.tinyInt()</code> / <code>.smallInt()</code> / <code>.bigInt()</code></li> <li><code>.uInteger()</code> / <code>.uTinyInt()</code> / <code>.uSmallInt()</code> / <code>.uBigInt()</code> \u2013 Unsigned</li> </ul> <p>Decimal:</p> <ul> <li><code>.decimal(total=8, places=2)</code></li> </ul> <p>Text:</p> <ul> <li><code>.string(length=255)</code> \u2013 VARCHAR</li> <li><code>.text()</code> \u2013 TEXT</li> </ul> <p>Boolean:</p> <ul> <li><code>.boolean()</code></li> </ul> <p>Date &amp; Time:</p> <ul> <li><code>.datetime()</code></li> <li><code>.date()</code></li> </ul>"},{"location":"docs/migrations/#column-modifiers","title":"Column Modifiers","text":"<ul> <li><code>.notNull()</code> \u2013 NOT NULL</li> <li><code>.nullable()</code> \u2013 Allow NULLs (removes NOT NULL on ALTER)</li> <li><code>.default(value)</code> \u2013 Static default</li> <li><code>.defaultNow()</code> \u2013 Use current timestamp</li> <li><code>.defaultFunction(func_name, param)</code> \u2013 Custom default function</li> </ul>"},{"location":"docs/migrations/#indexes","title":"Indexes","text":"<pre><code>with DWH().clean().alterTable('users') as table:\n    table.col('email').string().notNull()\n    table.indexUnique('email')\n</code></pre> <ul> <li><code>.indexUnique(column_name)</code> \u2013 Adds a UNIQUE INDEX</li> </ul>"},{"location":"docs/migrations/#foreign-keys","title":"Foreign Keys","text":"<p>For relational databases:</p> <pre><code>with DB().alterTable('posts') as table:\n    table.col('user_id').uBigInt().notNull()\n    table.foreignKey('user_id', ref_table='users', on_ref_col='id')\n</code></pre> <p>For data warehouses:</p> <pre><code>table.foreignKey(\n    'user_id',\n    ref_table='users',\n    on_ref_col='id',\n    ref_table_group=DWH().clean().layerName()\n)\n</code></pre>"},{"location":"docs/migrations/#python-query-builder-with-sqlglot-orm-style-syntax","title":"Python Query Builder (with SQLGlot ORM-style syntax)","text":"<p>Use Arkalos' built-in query builder to interact with your DB or DWH from notebooks, scripts, or your FastAPI app.</p> <pre><code>from arkalos import DB, DWH\nfrom pydantic import BaseModel\nimport polars as pl\nimport datetime\n\nclass UserType(BaseModel):\n    id: int\n    name: str\n    email: str\n    is_admin: bool = False\n    created_at: datetime.datetime\n    updated_at: datetime.datetime\n\nclass InsertUserType(BaseModel):\n    name: str\n    email: str\n    is_admin: bool = False\n\ndb = DB()\ndwh = DWH()\n\n# Connect before running queries\ndwh.connect()\n\n# Your queries here\n\n# Disconnect after\ndwh.disconnect()\n</code></pre>"},{"location":"docs/migrations/#raw-sql","title":"Raw SQL","text":"<pre><code>dwh.executeSql(\"INSERT INTO users ...\")\ndf = dwh.executeSql(\"SELECT ...\", select=True)  # Returns Polars DataFrame\n</code></pre>"},{"location":"docs/migrations/#ibis-tables","title":"Ibis Tables","text":"<pre><code>df = dwh.raw().selectAll('airtable__properties')\ntable = dwh.raw().table('notion__projects')  # ibis Table\n</code></pre> <p>See Ibis Tutorials for more.</p>"},{"location":"docs/migrations/#insert-records","title":"Insert Records","text":"<pre><code>db.insert('users', user)\n\n# or get inserted row\nuser = db.insertReturning('users', user)\n# or get inserted row as a full model type\ndb.insertReturning('users', user, UserType)\n\n# To insert multiple records:\ndb.insertMultiple('users', users)  # DataFrame or list of dicts\n</code></pre>"},{"location":"docs/migrations/#update","title":"Update","text":"<pre><code>user.is_admin = True\nres = db.update('users', user, 'email', user.email)\n</code></pre>"},{"location":"docs/migrations/#delete","title":"Delete","text":"<pre><code>dwh.clean().delete('users', 'email', 'test@example.com')\n</code></pre>"},{"location":"docs/migrations/#explore-schema","title":"Explore Schema","text":"<pre><code>dwh.printTablesAndColumns('raw')\n</code></pre>"},{"location":"docs/new-project/","title":"How to Create a New Python Project","text":"<p>Ensure all the requirements are met.</p>"},{"location":"docs/new-project/#starting-a-new-arkalos-project","title":"Starting a New Arkalos Project","text":"<pre><code># Create a new folder and Python project.\nuv init &lt;project_name&gt;\n\n# Navigate to the new folder\ncd &lt;project_name&gt;\n\n# Add and install all dependencies (this may take a few minutes)\nuv add arkalos\n\n# Set up the Arkalos starter project\nuv run arkalos init\n</code></pre> <p>This will install Arkalos along with dependencies like NumPy, SciPy, Polars, Pandas for data frames, matplotlib, Ollama, and more.</p> <p>Your project folder structure will be automatically set up.</p> <p>That's it \u2014 you're ready to start coding!</p>"},{"location":"docs/new-project/#creating-a-python-project-workspace-in-the-vs-code","title":"Creating a Python Project (Workspace) in the VS Code","text":"<ol> <li>Make sure you're in the project folder in the terminal.</li> <li>Run <code>code .</code> to open a new VS Code window in the current directory.</li> <li>Open the Project Manager extension from the side tab.</li> <li>In the side menu, hover under Favorites and click \"Save Project.\"</li> <li>Next time, easily open this project by double-clicking it in the Project Manager. To work on multiple projects, hover over the project name and click the \"Open in New Window\" icon on the right.</li> </ol>"},{"location":"docs/new-project/#working-on-an-existing-project","title":"Working on an Existing Project","text":"<pre><code>git pull &lt;your project repo&gt;\n\nuv sync\n\ncopy .env.example .env\n</code></pre>"},{"location":"docs/new-project/#folder-structure","title":"Folder Structure","text":"<p>Learn more about the Arkalos directory structure and where to organize your files.</p>"},{"location":"docs/notebooks/","title":"Writing Your First Python Project Code and Jupyter Notebook in the VS Code","text":"<p>This guide focuses on using VS Code with the Jupyter extension, as explained previously.</p> <p>You may need to install the development dependency:</p> <pre><code>uv add ipykernel --dev\n</code></pre>"},{"location":"docs/notebooks/#creating-a-new-ipynb-file","title":"Creating a New <code>.ipynb</code> File","text":"<p>Jupyter Notebooks are a great place to start exploring data, designing new code, experimenting, or prototyping.</p> <p>Notebooks contain cells where each cell functions like an independent script. You can run all cells or specific ones manually.</p> <p>When cells are run, all imported modules and declared variables are stored in memory and available in other cells. If a specific cell is skipped, its code won't be available in memory.</p> <p>Each cell has a single output displayed right after it. You can debug the code by printing variable values or, when analyzing data, display data frames (tables) first and generate visual charts in the next cell.</p> <p>Create a new <code>notebooks/my_notebook.ipynb</code> file inside the <code>notebooks/</code> folder.</p>"},{"location":"docs/notebooks/#first-cell","title":"First Cell","text":"<p>In the middle of the notebook, click on \"+ Code\" to add a new cell.</p> <p>In the top right corner of VS Code, select \"Select Kernel\" and choose the option that looks like:</p> <p><code>.venv (Python 3.13.1) .venv/bin/python</code>.</p> <p>Add this code to your first cell:</p> notebooks/my_notebook.ipynb (Cell 1)<pre><code>from arkalos import config, var_dump\n\npoint = {'x': 5, 'y': 10}\n\nvar_dump(point)\n</code></pre>"},{"location":"docs/notebooks/#running-and-resetting","title":"Running and Resetting","text":"<p>Click \"Run All\" at the top to execute all cells from the beginning.</p> <p>You can also run each cell individually by clicking the play triangle icon on the left of the cell.</p> <p>If something doesn't work properly, or if you modify custom modules in the <code>app/</code> folder after running a cell, click \"Restart\" to restart the Jupyter kernel and clear cache and memory.</p>"},{"location":"docs/notebooks/#another-cell","title":"Another Cell","text":"<p>You should see some output after running the first cell.</p> <p>Hover your mouse in the middle at the end of the output, and the \"+ Code\" button will appear. Click it to create the next cell.</p> <p>Alternatively, you can click the \"+ Code\" button in the top horizontal menu.</p> <p>Add this code to the new cell and run it:</p> notebooks/my_notebook.ipynb (Cell 2)<pre><code>config('app.name')\n</code></pre> <p>Unlike scripts, notebook cells automatically print the last variable or operation, so you don't need to use the <code>print()</code> function every time.</p> <p>You should see the name of your app as the output of this cell.</p>"},{"location":"docs/notebooks/#create-custom-modules","title":"Create Custom Modules","text":"<p>Remember from the Getting Started Guide the difference between Code to Run and Code to Reuse.</p> <p>While your initial thoughts about reusable functions, classes, configurations, or modules can start in a notebook or script, you should eventually move all reusable code into the <code>app/</code> directory.</p> <p>Let's create the <code>app/utils/my_utils.py</code> file, which will also act as a Python module. Add your first function there:</p> app/utils/my_utils.py<pre><code>from arkalos import config\n\ndef greet(greeting: str) -&gt; None:\n    print(greeting + ', ' + config('app.name'))\n</code></pre> <p>Now, consume your first reusable code and module in the notebook by creating a new cell and running it:</p> notebooks/my_notebook.ipynb (Cell 3)<pre><code>import app.utils.my_utils as my_utils\n\nmy_utils.greet('Hello')\n</code></pre>"},{"location":"docs/notebooks/#analyze-and-visualize-data","title":"Analyze and Visualize Data","text":"<p>Let's analyze and visualize some data from your Airtable or Notion database.</p> notebooks/my_notebook.ipynb (Cell 4)<pre><code>import pandas as pd\nfrom arkalos.data.extractors.notion_extractor import NotionExtractor\n# from arkalos.data.extractors.airtable_extractor import AirtableExtractor\n\nextractor = NotionExtractor()\n# extractor = AirtableExtractor()\n\n# Provide a table name from the .env file\ndata = extractor.fetchAllData('Tasks')  \n\ndf = pd.DataFrame(data)\n\ndf\n</code></pre> <p>Run this cell, and you should see a table.</p> <p>Finally, let's create a new cell to generate a pie chart.</p> <p>Assume you have a Tasks table with a \"Status\" column.</p> <p>This code will display a pie chart of task statuses by percentage:</p> notebooks/my_notebook.ipynb (Cell 5)<pre><code># \"Status\" is a column name. To access it use df.Status or df['Status']\ndf.Status.value_counts().plot(kind='pie', autopct='%1.0f%%', startangle=90)\n</code></pre> <p>Now update your Notion or Airtable by adding a new task and changing a few statuses. Then re-run all the cells and you will see an updated chart that reflects your data real-time.</p>"},{"location":"docs/notebooks/#from-notebook-to-scripts","title":"From Notebook to Scripts","text":"<p>Now that you have first experience writing code using Arkalos, let's continue and create our first script and run it from the terminal.</p>"},{"location":"docs/pages/","title":"React Router Pages for Python FastAPI","text":"<p>Arkalos comes with a ready-to-use frontend built with React and React Router 7, designed to work seamlessly with your FastAPI backend. This guide explains how to set up, structure, and extend your frontend pages.</p>"},{"location":"docs/pages/#requirements","title":"Requirements","text":"<p>To use the default frontend:</p> <p>Make sure you have the latest version of Node.js installed.</p> <p>Change into the <code>frontend</code> directory and install the dependencies:</p> <pre><code>cd frontend\nnpm install\n</code></pre> <p>To run the development server:</p> <pre><code>npm run dev\n</code></pre> <p>To build static files for production:</p> <pre><code>npm run build\n</code></pre>"},{"location":"docs/pages/#frontend-routes","title":"Frontend Routes","text":"<p>Frontend routes are registered in <code>frontend/app/app_routes.jsx</code> using React Router:</p> <pre><code>&lt;Route path=\"*\" element={&lt;_404NotFoundPage /&gt;} /&gt;\n&lt;Route path=\"/\" element={&lt;IndexPage /&gt;} /&gt;\n&lt;Route path=\"/dashboard\" element={&lt;DashboardPage /&gt;} /&gt;\n&lt;Route path=\"/chat\" element={&lt;AIChatPage /&gt;} /&gt;\n&lt;Route path=\"/logs\" element={&lt;LogsPage /&gt;} /&gt;\n</code></pre> <p>Each route maps a URL path to a specific Page Component.</p>"},{"location":"docs/pages/#pages","title":"Pages","text":"<p>Pages are React components stored in the <code>frontend/app/pages/</code> directory. Each page typically:</p> <ul> <li>Uses a layout (e.g., <code>MainLayout</code>)</li> <li>Sets the document <code>&lt;title&gt;</code></li> <li>Renders main content using standard React components</li> <li>Optionally fetches data from the backend using <code>fetch</code> and <code>FormData</code> APIs</li> </ul>"},{"location":"docs/pages/#layouts","title":"Layouts","text":"<p>Layouts are wrapper components that provide shared structure (e.g., navbar, footer). They live in <code>frontend/app/layouts/</code>.</p> <p>Arkalos includes a default layout:</p> <pre><code>import MainLayout from '@/layouts/MainLayout'\n</code></pre> <p>You can create additional layouts here for different sections or contexts of your app.</p>"},{"location":"docs/pages/#creating-a-new-page","title":"Creating a New Page","text":"<p>Let\u2019s walk through adding a simple \"About\" page.</p>"},{"location":"docs/pages/#1-create-the-page-component","title":"1. Create the Page Component","text":"<p>Create a new <code>frontend/app/pages/AboutPage.jsx</code> file:</p> frontend/app/pages/AboutPage.jsx<pre><code>import MainLayout from '@/layouts/MainLayout'\n\nexport default function AboutPage() {\n  return (\n    &lt;MainLayout title=\"About\"&gt;\n      &lt;h1&gt;About Page&lt;/h1&gt;\n      &lt;section&gt;\n        &lt;p&gt;Hi from my About page \ud83d\udc4b&lt;/p&gt;\n      &lt;/section&gt;\n    &lt;/MainLayout&gt;\n  )\n}\n</code></pre>"},{"location":"docs/pages/#2-register-the-route","title":"2. Register the Route","text":"<p>In <code>frontend/app/app_routes.jsx</code>, import and add the new route:</p> frontend/app/app_routes.jsx<pre><code>import AboutPage from '@/pages/AboutPage'\n\n&lt;Route path=\"/about\" element={&lt;AboutPage /&gt;} /&gt;\n</code></pre>"},{"location":"docs/pages/#3-add-to-the-navigation","title":"3. Add to the Navigation","text":"<p>In <code>frontend/app/components/Nav.jsx</code>:</p> frontend/app/components/Nav.jsx<pre><code>import { NavLink } from 'react-router-dom'\n\n&lt;NavLink to=\"/about\"&gt;About&lt;/NavLink&gt;\n</code></pre>"},{"location":"docs/registry/","title":"Registry and Bootstrapping","text":""},{"location":"docs/registry/#understanding-the-registry","title":"Understanding the Registry","text":"<p>A Registry is like a simple table that helps your code quickly find and use the right functions, classes, or modules. It\u2019s similar to a library catalog \u2014 you look up a book by its title and find out where to get it.</p> <p>Think of it this way:</p> <ul> <li>The first column is a short key (like a book title).</li> <li>The second column is where to find the book (who has it, or which shelf it\u2019s on).</li> </ul> <p>When you need a book, you don\u2019t care who has it at that moment \u2014 you just use the title to get it. Similarly, in coding, you don\u2019t always care which database or module is being used behind the scenes. You just ask for what you need, and the Registry finds the right tool for the job.</p> <p>The advantage? You can swap out one tool for another without rewriting your entire codebase \u2014 just like borrowing the same book from a different library branch.</p> <p>The concept of Registry and retrieving dependencies dynamically is widely used across multiple fields under different names, e.g: Lookup Table, Dynamic Linker, Feature Store, Dependency Injection (DI), Service Container, Factory, Inventory System, Ledger, Dynamical System and Dynamic State Selection, Neural Memory Retrieval, Schema Theory, Theory of Forms, and Category Theory.</p>"},{"location":"docs/registry/#getting-modules-from-the-registry","title":"Getting Modules from the Registry","text":"<p>In Arkalos, you can retrieve functions and modules from the Registry using a simple command:</p> <pre><code>from arkalos import Registry\n\nconfig_func = Registry.get('config')\nconfig_func('app.name')\n</code></pre> <p>This is the same as doing:</p> <pre><code>from arkalos import config\nconfig('app.name')\n</code></pre>"},{"location":"docs/registry/#why-use-the-registry","title":"Why use the Registry?","text":"<p>Using a Registry allows for flexibility. The <code>config()</code> function itself retrieves the actual configuration function from the Registry before running it. This means you can replace the default <code>config()</code> function with your own custom version when needed.</p> <p>For example, let\u2019s say you want to override the built-in configuration system with your own:</p> <pre><code>from typing import Optional\n\nfrom arkalos import Registry\n\ndef my_config(key: str, default: Optional[str]=None) -&gt; str:\n    return f\"Custom config for {key}\"\n\nRegistry.register('config', my_config)\n\nfrom arkalos import config\n\n# Now this will return our custom message instead of the default behavior\nprint(config('app.name'))  # Output: Custom config for app.name\n</code></pre> <p>With this approach, any script using <code>config('app.name')</code> will now call your custom function instead of the default one.</p>"},{"location":"docs/registry/#registering-classes","title":"Registering Classes","text":"<p>Arkalos comes with a few other utility functions that retrive the same object of the same class and a contract.</p> <pre><code>from arkalos import Log, dwh\n</code></pre> <p><code>Log</code> is a module wrapper around the Logger class that comes from the Registry.</p> <p><code>dwh()</code> is a simple helper function that allows you to retrive the data warehouse from any part of your application or a script.</p> <pre><code>print(dwh().NAME)    # SQLite\n</code></pre> <p>You can register classes the same way:</p> <pre><code>from arkalos import Registry\n\nclass MyClass:\n    def myAction(self):\n        print('My action')\n\nRegistry.register('my_component', MyClass)\n\ndef my_component():\n    return Registry.get('my_component')\n\nmy_component().myAction()\n</code></pre>"},{"location":"docs/registry/#bootstrapping-setting-up-your-project","title":"Bootstrapping: Setting Up Your Project","text":"<p>Bootstrapping is the process of setting up and starting your application \u2014 just like how a computer boots up when you turn it on.</p> <p>When you develop an app or run scripts frequently, you might want to add global setup logic that runs every single time before anything else. For example, if your app depends on a database or external service, you can configure it at the start.</p> <p>Arkalos includes a default file for this: <code>app/bootstrap.py</code>. This file acts as a global setup script.</p> <p>Here\u2019s what it looks like by default:</p> app/bootstrap.py<pre><code>from arkalos import Registry\n\ndef run():\n    pass  # You can register custom modules here\n    # Registry.register('my_module', my_module)\n</code></pre>"},{"location":"docs/registry/#how-to-use-bootstrapping","title":"How to Use Bootstrapping","text":"<p>Before running any script, you can bootstrap your project by adding this at the top of your file:</p> <pre><code>import app.bootstrap as bootstrap\nbootstrap.run()\n</code></pre> <p>This ensures all necessary configurations and modules are properly set up before the rest of your script runs.</p>"},{"location":"docs/registry/#why-this-matters","title":"Why This Matters","text":"<p>Using a Registry and Bootstrapping helps keep your code organized, flexible, and scalable. With these tools, you can:</p> <ul> <li>Easily swap out modules or functions without rewriting code.</li> <li>Set up global settings that apply across your entire project.</li> <li>Keep your scripts clean by handling setup logic in one place.</li> </ul>"},{"location":"docs/registry/#what-next","title":"What Next","text":"<p>Congratulations! You have completed the Writing Basic Code guide and can start writing Arkalos code!</p> <p>You may explore the next section about Data Sources &amp; Extractors</p>"},{"location":"docs/routes/","title":"Multiple Route Files in Python FastAPI","text":"<p>Arkalos HTTP server runs on top of Uvicorn and uses an extended FastAPI app for handling HTTP routes.</p> <p>In an Arkalos project you may have both frontend and backend parts, or just use Arkalos for backend API as a microservice.</p> <p>The default frontend setup is React + Vite + React Router (RR7), located in the <code>frontend</code> folder. You can replace this with your own frontend, remve it or keep it.</p> <p>This guide focuses on the Python backend \u2014 specifically, how to define API routes using multiple files.</p>"},{"location":"docs/routes/#what-are-routes","title":"What Are Routes?","text":"<p>Routes are simply URLs \u2014 like <code>/</code> or <code>/products/123</code> \u2014 that return data to your frontend or another service. Each route is linked to a Python function that handles the request and returns data.</p> <p>Arkalos uses a modern Three-Tier Architecture, or a familiar structure similar to MVC (Model\u2013View\u2013Controller). Think of routes as your \"controllers\" or \"actions\", functions you call on a server when a request arrives.</p>"},{"location":"docs/routes/#organizing-routes-in-files","title":"Organizing Routes in Files","text":"<p>All your route files live inside <code>app/http/routes/</code> folder.</p> <p>Each file typically matches one feature or domain \u2014 like <code>reports.py</code>, <code>auth.py</code>, or <code>users.py</code>.</p> <p>Note</p> <p>Arkalos automatically finds and installs all routes in this folder. No need to import or register them manually.</p>"},{"location":"docs/routes/#a-simple-route-example","title":"A Simple Route Example","text":"<p>Let's say you want to show reports about the data you analyzed. Create a new route file <code>app/http/routes/reports.py</code>:</p> app/http/routes/reports.py<pre><code>from arkalos import router\n\n@router.get('/reports')\nasync def reports():\n    return {'message': 'Hi from Arkalos API endpoint!'}\n</code></pre>"},{"location":"docs/routes/#adding-data-to-routes","title":"Adding Data to Routes","text":"<p>Let's say you want to return a dataset, like one from a Jupyter Notebook:</p> app/http/routes/reports.py<pre><code>from vega_datasets import data as datasets # type: ignore\nimport polars as pl\nfrom arkalos import router\n\n@router.get('/reports')\nasync def reports():\n    cars_df = datasets.cars()\n    df = pl.from_pandas(cars_df)\n    return df.write_json()\n</code></pre> <p>Note</p> <p>All backend routes must return JSON-serializable data \u2014 typically a dictionary or JSON-like structure. This makes them compatible with frontend apps and fetch calls.</p>"},{"location":"docs/routes/#running-the-server-and-testing","title":"Running the Server and Testing","text":"<p>Make sure your server is running:</p> <pre><code>uv run arkalos serve\n</code></pre> <p>Then to test your API endpoints, visit your API in the browser: <code>http://127.0.0.1:8000/api/reports</code>.</p> <p>Note</p> <p>All backend routes are prefixed with <code>/api</code></p> <p>You can also test using tools like Postman or your browser\u2019s DevTools. If you're using Edge, check out Network Console.</p>"},{"location":"docs/routes/#routes-with-parameters","title":"Routes with Parameters","text":"<p>Routes, like functions, can accept parameters from the request.</p> <p>There are HTTP methods, such as GET and POST. GET is the default method used to retrieve the data, and POST \u2014 to submit the form.</p> <p>GET has two ways of dealing with parameters:</p>"},{"location":"docs/routes/#using-query-parameters-get","title":"Using Query Parameters (GET)","text":"<p>First. Search query parameters are commonly used on the same page to filter the data on that page.</p> <p>Want to filter data with URL parameters like <code>?origin=japan</code>?</p> app/http/routes/reports.py<pre><code>from vega_datasets import data as datasets # type: ignore\nimport polars as pl\nfrom arkalos import router\n\n@router.get('/reports')\nasync def reports(origin: str | None = None):\n    cars_df = datasets.cars()\n    df = pl.from_pandas(cars_df)\n\n    if origin:\n        df = df.filter(pl.col('Origin').str.to_lowercase() == origin.lower())\n\n    return df.write_json()\n</code></pre> <p>Visit: <code>http://127.0.0.1:8000/api/reports?origin=japan</code></p>"},{"location":"docs/routes/#using-path-parameters-get-404-response","title":"Using Path Parameters (GET) &amp; 404 Response","text":"<p>Second. Paths are usually used for different pages or categories.</p> <p>Want the parameter inside the path itself, like <code>/reports/japan</code>?</p> app/http/routes/reports.py<pre><code>from vega_datasets import data as datasets # type: ignore\nimport polars as pl\n\nfrom arkalos import router\nfrom arkalos.http import response\n\n@router.get('/reports/{origin}')\nasync def reports_by_origin(origin: str):\n    cars_df = datasets.cars()\n    df = pl.from_pandas(cars_df)\n    df = df.filter(pl.col('Origin').str.to_lowercase() == origin.lower())\n\n    if df.is_empty():\n        return response('Category not found', 404)\n\n    return df.write_json()\n</code></pre> <p>Visit: <code>http://127.0.0.1:8000/api/reports/japan</code></p> <p>In the case of the path, we use <code>response(data, status_code)</code> helper function to return 404 Page not Found response if the category is not found.</p>"},{"location":"docs/routes/#using-post-formdata-parameters","title":"Using POST &amp; FormData Parameters","text":"<p>POST is used when sending data, like a form submission, such as a chat message.</p> <p>You define a data class to receive the form data:</p> app/http/routes/reports.py<pre><code>from fastapi import Form, Depends\n\nfrom arkalos import router\n\n@dataclass\nclass ChatRequest:\n    message: str = Form(...)\n\n@router.post('/reports/chat')\nasync def reports_chat(request: ChatRequest = Depends()):\n    print('User said: ', request.message)\n    # Here you could trigger an AI agent or save to DB\n</code></pre> <p>Another example:</p> <pre><code>@dataclass\nclass Report:\n    title: str = Form(...)\n    description: str = Form(...)\n\n@router.post('/reports/create')\nasync def reports_create(report: Report = Depends()):\n    print('Creating report:', report.title)\n    # Save to database or process\n</code></pre>"},{"location":"docs/routes/#error-handling-and-500-response","title":"Error Handling and 500 Response","text":"<p>Note</p> <p>Arkalos automatically catches errors and returns 500 response in a clear JSON format:</p> <pre><code>@router.get('/reports-error')\nasync def reports_error():\n    raise Exception(\"Something went wrong\")\n</code></pre> <p>Response:</p> <pre><code>{\"error\": \"Something went wrong\"}\n</code></pre> <p>Or a code mistake:</p> <pre><code>@router.get('/reports-error')\nasync def reports_error():\n    a  # Will return the error message with NameError\n</code></pre> <p>Note</p> <p>Errors and info logs are saved in <code>data/logs/</code> folder in JSONL (JSON Lines) format. You can view them in the Frontend UI \u2192 Logs Page, or in your terminal during development.</p>"},{"location":"docs/scripts/","title":"Python Scripts","text":"<p>Scripts are simple programs that run tasks automatically. Unlike Notebooks, they don't need a UI like Jupyter and can be run from the terminal, a server, or even as an API. They're great for automating workflows, launching a microserver or an agent.</p>"},{"location":"docs/scripts/#why-use-scripts","title":"Why Use Scripts?","text":"<p>Your reusable code lives in the <code>app/</code> folder, but it won't do anything by itself. Scripts are how you make that code run \u2014 whether it's a data pipeline, analysis, automation, AI agent or an app.</p>"},{"location":"docs/scripts/#types-of-scripts","title":"Types of Scripts","text":"<ol> <li> <p>One-Time Scripts: These scripts run once and stop. Think of tasks like analyzing data or running an ETL process to load data into a warehouse.</p> </li> <li> <p>Continuous Scripts: These run non-stop, like a web server or a chatbot that stays active in your terminal. They keep running until you stop them manually.</p> </li> </ol>"},{"location":"docs/scripts/#your-first-script","title":"Your First Script","text":"<p>First, create a utility module inside <code>app/utils/</code> folder:</p> app/utils/my_utils.py<pre><code>from arkalos import config\n\ndef greet(greeting: str) -&gt; None:\n    print(f\"{greeting}, {config('app.name')}\")\n</code></pre> <p>Now, create your first script inside <code>scripts/cli/</code> folder.</p> scripts/cli/my_script.py<pre><code>import app.utils.my_utils as my_utils\n\nGREETING = \"Hello\"\n\nprint('Running my script...')\nmy_utils.greet(GREETING)\nprint('Done. Bye!')\n</code></pre>"},{"location":"docs/scripts/#running-scripts","title":"Running Scripts","text":"<p>To run your script, use the terminal command <code>uv run &lt;path&gt;</code>:</p> <pre><code>uv run scripts/cli/my_script.py\n</code></pre> <p>While typing the path, use Tab for autocompletion.</p>"},{"location":"docs/scripts/#adding-arguments-to-scripts","title":"Adding Arguments to Scripts","text":"<p>Scripts can take inputs, just like functions. Update your script to accept a greeting message:</p> scripts/cli/my_script.py<pre><code>import argparse\nimport app.utils.my_utils as my_utils\n\nparser = argparse.ArgumentParser(description=\"My Greeting Script\")\nparser.add_argument('greeting', metavar='&lt;greeting&gt;', help='A greeting message')\nargs = parser.parse_args()\n\nprint('Running my script...')\nmy_utils.greet(args.greeting)\nprint('Done. Bye!')\n</code></pre> <p>Run it with an argument (add quotes if there are spaces):</p> <pre><code>uv run scripts/cli/my_script.py \"Hello World\"\n</code></pre> <p>For help, type:</p> <pre><code>uv run scripts/cli/my_script.py -h\n</code></pre>"},{"location":"docs/scripts/#script-example-import-data-into-a-warehouse","title":"Script Example: Import Data into a Warehouse","text":"<p>Let's pull data from your Airtable or Notion into a local data warehouse.</p> <p>Create a new script:</p> scripts/etl/sync_airtable_dwh.py<pre><code>from arkalos.data.extractors.airtable_extractor import AirtableExtractor\n# or for Notion\n# from arkalos.data.extractors.notion_extractor import NotionExtractor\nfrom arkalos.workflows.etl_workflow import ETLWorkflow\n\nwf = ETLWorkflow(AirtableExtractor)\nwf.run(drop_tables=True)\n</code></pre> <p>Run it:</p> <pre><code>uv run scripts/etl/sync_airtable_dwh.py\n</code></pre> <p>You'll find your data in <code>data/dwh/dwh.db</code>. Now you can analyze data offline!</p>"},{"location":"docs/scripts/#script-example-talk-to-your-data","title":"Script Example: Talk to Your Data","text":"<p>Now, let's chat with your data using AI.</p> <p>First, make sure the Ollama server is running. In VS Code in the terminal section at the bottom, you can press \"+\" to open a new terminal tab and run ollama server there.</p> <pre><code>ollama serve\n</code></pre> <p>Create a new script:</p> scripts/ai/dwh_agent.py<pre><code>from arkalos.ai.agents import DWHAgent\n\nagent = DWHAgent()\nagent.run()\n</code></pre> <p>Run the agent:</p> <pre><code>uv run scripts/ai/dwh_agent.py\n</code></pre> <p>Now you can ask questions like:</p> <ul> <li>What tables do we have?</li> <li>Show me all tasks.</li> <li>Show rooms with a balcony.</li> </ul> <p>Type <code>exit</code> to stop the agent.</p>"},{"location":"docs/scripts/#stopping-scripts","title":"Stopping Scripts","text":"<p>To stop a long-running script, press <code>Ctrl + D</code> or <code>Ctrl + C</code> in your terminal.</p>"},{"location":"docs/scripts/#next-steps","title":"Next Steps","text":"<p>Now that you've learned about the Code to Run (notebooks and scripts), check out the next Code to Reuse (App &amp; Modules) guide to organize your reusable code.</p>"},{"location":"docs/structure/","title":"Python Project Directory Structure","text":"<p>Arkalos folder structure ensures that your project is well-organized, separating code to run from code to reuse, and helps you with growing your project, aligning teams, and easily manage modules, configuration, notebooks, scripts, data, and documentation.</p> <p>You can utilize this structure for any project from basic customer research, academic project, a chatbot in the terminal, a personal assistant, to IoT, robotics and autonomous vehicles (AVs).</p> <pre><code>app/\n    _private/               # Git-ignored folder for personal or work-in-progress code\n    ai/                     # AI and ML code\n        actions/            # AI actions and tasks that agents can perform\n        agents/             # AI agents (e.g., chatbots, assistants, robots, AVs)\n        evals/              # AI model evaluation tools\n        trainers/           # Model training and fine-tuning modules\n    algorithms/             # Custom algorithms and computational logic\n    cli/                    # Command Line Interface tools\n    core/                   # Core app logic and Arkalos extensions\n    data/                   # Data extraction, transformation, analysis, warehousing\n        analyzers/          # Data analysis modules (e.g., classification, clustering)\n        extractors/         # Data source connectors and extraction tools\n        transformers/       # Data cleaning, normalization, and transformation tools\n        types/              # Custom data types (data contracts)\n        visualizers/        # Data visualization, charts, graphs and plots\n        warehouse/          # Data warehouse setup and loaders\n    hadrware/               # Interfaces for hardware and robotics\n        actuators/          # Drivers/interfaces to control physical actuators (e.g; motors, arms)\n        communicators/      # Protocols and data exchange between hardware components (e.g; Ethernet)\n        controllers/        # Strategies/algorithms to regulate actuator behavior based on sensor feedback\n        sensors/            # Drivers for sensor and environment data acquisition (e.g., vision)\n    http/                   # HTTP servers, APIs, dashboards, and microservices\n        controllers/        # HTTP web controllers to bundle multiple actions and routes\n        middleware/         # HTTP web middleware logic to run between requests\n        routes/             # HTTP web routes to expose the app externally via web URLs\n    jobs/                   # Background tasks, queues, and cron jobs\n    services/               # Services and systems, e.g. API connectors\n    utils/                  # Utility functions and helpers\n    workflows/              # Multi-step workflows (e.g., data pipelines, automation)\n        ai/                 # AI-specific workflows (config, training, evaluation)\n        etl/                # Data extraction, crawling, transformation, and loading workflows\n        experiments/        # Scientific experiments and hypothesis testing\n        gen/                # Data generation workflows for testing\n        processes/          # Business processes and other automation workflows\n\nconfig/                     # Configuration files with Python logic, works with .env\n\ndata/                       # Git-ignored data folder, used manually and by Arkalos\n    drive/                  # Main storage for raw data, PDFs, CSVs, images, etc.\n    dwh/                    # Data warehouse data. Auto-generated schema and cache\n    gen/                    # Automatically generated data for testing\n    keys/                   # Secret keys for API authentication and services\n    logs/                   # Logs generated by Arkalos (`arkalos-&lt;year&gt;-&lt;month&gt;.log`)\n    models/                 # Trained AI models saved here\n    tokens/                 # Automatically generated and stored auth tokens\n\ndocs/                       # Project documentation (usage, modules, contributions)\n\nnotebooks/                  # Jupyter Notebooks for exploration and prototyping\n    _private/               # Git-ignored folder for personal notebook drafts\n\nscripts/                    # Stand-alone executable scripts\n    _private/               # Git-ignored folder for personal scripts\n    ai/                     # Scripts to train models or run AI agents\n    cli/                    # Command Line Interface scripts\n    etl/                    # Data workflows: extraction, transformation, loading\n    experiments/            # Prototyping, exploration, and scientific experiments\n    gen/                    # Scripts to generate test data\n    http/                   # Serve APIs, microservices, dashboards, or web apps\n    jobs/                   # Scheduled tasks, background jobs, and cron jobs\n    processes/              # Business processes and automation scripts\n\ntests/                      # Unit and other tests for your code\n</code></pre>"},{"location":"docs/structure/#private-code-inside-_private-folders","title":"Private code inside <code>_private</code> folders","text":"<p>In the Arkalos project, various folders named <code>_private/</code> are gitignored.</p> <p>This means when you share your code with the team and push it to a Git repository (e.g., GitHub), any files inside these <code>_private</code> folders won\u2019t be shared or committed.</p> <p>If you're working alone, you can ignore such folders.</p> <p>In a team setting, use it to create preliminary versions of your code or work-in-progress files without worrying about accidentally committing them.</p>"},{"location":"docs/structure/#code-to-run-notebooks-and-scripts","title":"Code to Run: <code>notebooks/</code> and <code>scripts/</code>","text":"<p>All runnable code should be placed in either the <code>notebooks/</code> or <code>scripts/</code> folders.</p> <p>Typically, you start by exploring data, experimenting, or prototyping in a Jupyter Notebook.</p> <p>Once ready, convert your work into stand-alone scripts that you and your team can run from the terminal.</p>"},{"location":"docs/structure/#code-to-reuse-and-consume-app","title":"Code to Reuse and Consume: <code>app/</code>","text":"<p>Place any code you want to reuse across notebooks or scripts \u2014 such as functions, classes, modules, or packages \u2014 in subfolders inside the <code>app/</code> directory.</p> <p>Avoid having variables in the global scope, and ensure no code runs on import.</p>"},{"location":"docs/structure/#code-to-run-vs-code-to-reuse","title":"Code to Run vs. Code to Reuse:","text":"<p>Organize your code as follows:</p> <ul> <li><code>notebooks/</code> \u2013 Jupyter Notebooks for exploration and prototyping</li> <li><code>scripts/</code> \u2013 Stand-alone scripts to execute</li> <li><code>app/</code> \u2013 Reusable code (functions, constants, modules, classes, packages)</li> </ul> <p>Example of code that belongs in <code>scripts/</code>:</p> scripts/cli/example.py<pre><code>import app.utils.my_module as my_module\n\nx = 5\nprint(my_module.my_func(x))\n</code></pre> <p>Example of reusable code that belongs in <code>app/</code>:</p> app/utils/my_module.py<pre><code>def my_func(x):\n    return x + 5\n</code></pre>"},{"location":"docs/structure/#other-primary-folders","title":"Other Primary Folders","text":"<p>In addition to <code>notebooks/</code>, <code>scripts/</code>, and <code>app/</code>, the root of your project includes:</p> <ul> <li><code>config/</code> \u2013 Configuration files that work with the <code>.env</code> file. These are actual Python files and can include conditional logic, unlike simple text-based configs.  </li> <li><code>data/</code> \u2013 Upload raw data, analysis files, or secret keys here. Arkalos will also automatically store files such as data warehouse contents or trained models. This folder is git-ignored.  </li> <li><code>docs/</code> \u2013 Optional: Document your project, including module descriptions, usage instructions, and contribution guidelines.  </li> <li><code>tests/</code> \u2013 Write tests to ensure your code works as expected.</li> </ul>"},{"location":"docs/structure/#subfolders","title":"Subfolders","text":"<p>Let\u2019s dive into the subfolders inside <code>app/</code>, <code>data/</code>, and <code>scripts/</code>.</p>"},{"location":"docs/structure/#app","title":"<code>app/</code>","text":"<p>This folder contains reusable code organized into:</p> <ul> <li><code>app/ai/</code> \u2013 AI and ML code, including agents, environments, tasks, model trainers, and evaluations.  </li> <li><code>app/algorithms/</code> \u2013 Custom computational logic when standard libraries aren\u2019t enough.  </li> <li><code>app/cli/</code> \u2013 Custom Command Line Interface tools and commands.  </li> <li><code>app/core/</code> \u2013 Core, initialization, or bootstrapping logic, and Arkalos extensions.  </li> <li><code>app/data/</code> \u2013 Data contracts (types), extraction, transformation, analysis, and warehousing.  </li> <li><code>app/hardware/</code> \u2013 Interfaces for hardware and robotics (e.g. camera, vision, motors, wifi).</li> <li><code>app/http/</code> \u2013 Expose your project as an HTTP API, microservice, or full web UI/dashboard.  </li> <li><code>app/jobs/</code> \u2013 Background tasks, queues, and cron jobs.  </li> <li><code>app/services/</code> \u2013 Services and systems, e.g. API connectors</li> <li><code>app/utils/</code> \u2013 Utility functions extending Python's standard capabilities.  </li> <li><code>app/workflows/</code> \u2013 Multi-step workflows like data pipelines, business processes, or automation.</li> </ul>"},{"location":"docs/structure/#appai","title":"<code>app/ai/</code>","text":"<p>Every AI agent will typically include an <code>Agent</code> class and a <code>Task</code> it can perform.</p> <ul> <li><code>app/ai/actions/</code> \u2013 Actions, tasks, tools, or skills that agents can perform.  </li> <li><code>app/ai/agents/</code> \u2013 AI agents, from simple chatbots to complex robotics and autonomous vehicles.   </li> <li><code>app/ai/evals/</code> \u2013 Tools and modules for evaluating AI models.  </li> <li><code>app/ai/trainers/</code> \u2013 Modules for training and fine-tuning AI models.</li> </ul>"},{"location":"docs/structure/#appdata","title":"<code>app/data/</code>","text":"<ul> <li><code>app/data/analyzers/</code> \u2013 Modules for exploring and analyzing data (e.g., classification, clustering).  </li> <li><code>app/data/extractors/</code> \u2013 Data sources, connectors, and extraction tools.  </li> <li><code>app/data/transformers/</code> \u2013 Tools for data cleaning, normalization, and advanced transformations.</li> <li><code>app/data/types/</code> \u2013 Custom data types (data contracts)</li> <li><code>app/data/visualizers/</code> \u2013 Data visualization, charts, graphs, plots.  </li> <li><code>app/data/warehouse/</code> \u2013 Your custom data warehouse setup and loaders.</li> </ul>"},{"location":"docs/structure/#apphardware","title":"<code>app/hardware/</code>","text":"<ul> <li><code>app/hardware/actuators/</code> \u2013 Drivers/interfaces to control physical actuators (e.g; motors, arms).</li> <li><code>app/hardware/communicators/</code> \u2013 Protocols and data exchange between hardware components (e.g; Ethernet).</li> <li><code>app/hardware/controllers/</code> \u2013 Strategies/algorithms to regulate actuator behavior based on sensor feedback.</li> <li><code>app/hardware/sensors/</code> \u2013 Drivers for sensor and environment data acquisition (e.g., vision).</li> </ul>"},{"location":"docs/structure/#apphttp","title":"<code>app/http/</code>","text":"<ul> <li><code>app/http/controllers/</code> \u2013 HTTP web controllers to bundle multiple actions and routes.</li> <li><code>app/http/middleware/</code> \u2013 HTTP web middleware logic to run between requests.</li> <li><code>app/http/routes/</code> \u2013 HTTP web routes to expose the app externally via web URLs.</li> </ul>"},{"location":"docs/structure/#appworkflows","title":"<code>app/workflows/</code>","text":"<ul> <li><code>app/workflows/ai/</code> \u2013 AI workflows, including model configuration, training, and evaluation.  </li> <li><code>app/workflows/etl/</code> \u2013 Data workflows and pipelines, covering extraction, transformation, and loading.  </li> <li><code>app/workflows/experiments/</code> \u2013 Scientific experiments, hypothesis testing, and advanced workflows.  </li> <li><code>app/workflows/gen/</code> \u2013 Workflows to generate basic data, usually for testing.  </li> <li><code>app/workflows/processes/</code> \u2013 Business processes and other automation workflows.</li> </ul>"},{"location":"docs/structure/#data","title":"<code>data/</code>","text":"<p>All files in <code>data/</code> are git-ignored.</p> <p>Most subfolders are used automatically by Arkalos, but you\u2019ll manually manage files in <code>drive/</code> and <code>keys/</code>.</p> <p>For sharing files with your team, use cloud storage (e.g., Google Drive) or a separate repository.</p> <p>Subfolders:</p> <ul> <li><code>data/drive/</code> \u2013 Your main data storage, similar to a personal drive or cloud storage. Store PDFs, CSVs, images, videos, raw data, or training datasets here.  </li> <li><code>data/dwh/</code> \u2013 The data warehouse. By default, SQLite is used, and its schema, cache, and data are auto-generated here.  </li> <li><code>data/gen/</code> \u2013 Automatically generated data, typically for testing purposes.  </li> <li><code>data/keys/</code> \u2013 Secret keys for services like Google Cloud API or enterprise servers.  </li> <li><code>data/logs/</code> \u2013 Logs generated by Arkalos. Default file format: <code>arkalos-&lt;year&gt;-&lt;month&gt;.log</code>.  </li> <li><code>data/models/</code> \u2013 Save trained AI model outputs here.</li> </ul>"},{"location":"docs/structure/#scripts","title":"<code>scripts/</code>","text":"<p>Scripts often import and run workflows or services from the <code>app/workflows/</code> directory. They are Code to Run, while <code>app/</code> contains Code to Reuse.</p> <p>Subfolders:</p> <ul> <li><code>scripts/ai/</code> \u2013 AI-related scripts, like training models or running agents.  </li> <li><code>scripts/cli/</code> \u2013 Command Line Interface scripts for managing your workspace.  </li> <li><code>scripts/etl/</code> \u2013 Data extraction, transformation, and loading workflows.  </li> <li><code>scripts/experiments/</code> \u2013 Scripts for exploration, prototyping, and hypothesis testing.  </li> <li><code>scripts/gen/</code> \u2013 Scripts to generate basic or testing data.  </li> <li><code>scripts/http/</code> \u2013 Serve your app as an internal API, microservice, dashboard, or public web server.  </li> <li><code>scripts/jobs/</code> \u2013 Background tasks, queues, and cron jobs that run on a schedule.  </li> <li><code>scripts/processes/</code> \u2013 Business process automation and other workflows.</li> </ul>"},{"location":"docs/structure/#configuring","title":"Configuring","text":"<p>Now that you know where to organize your files, the next step is understanding the configuration files included with Arkalos, such as inside <code>config/app.py</code>, <code>.env.example</code>, <code>.env</code> and the <code>app/bootstrap.py</code>.</p> <p>Read next: Configuration &amp; Env.</p>"},{"location":"docs/styles/","title":"Styling React Router Frontend for Python FastAPI Backend with CSS","text":"<p>Arkalos uses vanilla CSS for full control over styling while keeping the setup simple and lightweight. All styles live in the <code>frontend/app/css/</code> directory and are bundled together via a central <code>_app.css</code> file.</p>"},{"location":"docs/styles/#main-entry-point-_appcss","title":"Main Entry Point: \"_app.css\"","text":"<p>The file <code>frontend/app/css/_app.css</code> acts as the main entry point. It does not contain direct styles but instead assembles all your CSS modules:</p> frontend/app/css/_app.css<pre><code>@import \"_vars\";\n@import \"_core\";\n\n@import \"link\";\n@import \"form\";\n@import \"button\";\n@import \"label\";\n@import \"loader\";\n@import \"nav\";\n@import \"table\";\n@import \"pagination\";\n@import \"card\";\n@import \"grid\";\n@import \"chart\";\n@import \"metric\";\n\n@import \"index\";\n\n@import \"chat/chat\";\n@import \"chat/message\";\n@import \"chat/markdown\";\n</code></pre> <p>Note</p> <p>Always import <code>_vars.css</code> and <code>_core.css</code> first, followed by component styles and custom page styles last.</p>"},{"location":"docs/styles/#defining-css-variables","title":"Defining CSS Variables","text":"<p>Use <code>frontend/app/css/_vars.css</code> to define or override global CSS variables:</p> frontend/app/css/_vars.css<pre><code>:root {\n  --base-font-size: 16px;\n  --base-font-color: #f1f1f1;\n}\n</code></pre> <p>These variables are then used across all stylesheets:</p> <pre><code>.my-button {\n  color: var(--base-font-color);\n}\n</code></pre>"},{"location":"docs/styles/#global-layout-and-typography","title":"Global Layout and Typography","text":"<p>The <code>frontend/app/css/_core.css</code> file handles:</p> <ul> <li>Reset styles (normalize)</li> <li>Global typography</li> <li>HTML and body layout</li> </ul> <p>Example:</p> frontend/app/css/_core.css<pre><code>html,\nbody {\n  background-color: var(--base-bg-color);\n}\n</code></pre>"},{"location":"docs/styles/#component-specific-css","title":"Component-Specific CSS","text":"<p>Each UI component or page section typically has its own CSS file. For example:</p> <ul> <li><code>form.css</code> \u2014 styles for form elements</li> <li><code>nav.css</code> \u2014 styles for the navigation bar</li> <li><code>card.css</code> \u2014 styles for content cards</li> <li><code>chat/message.css</code> \u2014 styles specific to chat messages</li> </ul> <p>This separation helps you keep styles clean and modular.</p>"},{"location":"docs/styles/#adding-new-styles","title":"Adding New Styles","text":"<p>When creating a new component or page:</p> <ol> <li>Create a new CSS file inside <code>frontend/app/css/</code>, e.g. <code>my-widget.css</code></li> <li>Define your styles:</li> </ol> my-widget.css<pre><code>.my-widget {\n  padding: 1rem;\n  border: 1px solid #ccc;\n  background: #fff;\n}\n</code></pre> <ol> <li>Import the new file at the end of <code>_app.css</code>:</li> </ol> _app.css<pre><code>@import \"my-widget\";\n</code></pre> <ol> <li>Then use it in your component:</li> </ol> <pre><code>export default function MyWidget() {\n  return &lt;div className=\"my-widget\"&gt;Hello!&lt;/div&gt;\n}\n</code></pre>"},{"location":"docs/teamwork/","title":"Working as a Team","text":"<p>Frequently commit your changes with git and push them to a GitHub or other repository so your teammates, school, or organization can access your code.</p> <p>Even if you work alone, using Git helps you share your code between multiple devices. For example, you can work or study at home or in a caf\u00e9 and then continue from your class, library, or office the next day.</p>"},{"location":"docs/teamwork/#where-to-start-writing-app-code","title":"Where to Start Writing App Code?","text":"<p>Check the folder structure guide to understand the default Arkalos project layout. However, you are not required to follow it strictly. Feel free to remove unnecessary folders and adjust the structure to fit your project.</p> <p>For example:</p> <ul> <li>If your project covers multiple domains or departments, you can create an <code>app/domains/</code> folder.</li> <li>If you are building a native desktop app, you might add an <code>app/ui/</code> folder.</li> <li>If developing a game engine, you can use the default <code>app/core/</code> folder or create <code>app/engine/</code>.</li> </ul>"},{"location":"docs/teamwork/#stem-students-teachers-schools-and-universities","title":"STEM Students, Teachers, Schools, and Universities","text":"<p>If you are a STEM student or self-learning math, statistics, or ML, you can write your implementations in the <code>app/algorithms/</code> folder, separate from notebooks.</p> <p>For schools and universities, a single Arkalos repository can host all class materials, including default modules and Notebook templates. You may organize code by a topic or a year using subfolders, such as <code>notebooks/ml101/</code> and <code>notebooks/ml102/</code>.</p>"},{"location":"docs/teamwork/#data-analysis-etl-migration-visualization-and-warehousing","title":"Data Analysis, ETL, Migration, Visualization, and Warehousing","text":"<p>For working with data (custom types, transformation, visualization, extraction, or analysis), use the <code>app/data/</code> folder. This is different from the <code>data/</code> folder, which stores downloaded files and datasets.</p> <p>If you are an indepedent data analyst, researcher, freelancer, consultant, or an agency, you do not have to create a new Arkalos project every time and can simply create a folder for each client while sharing the same app code, e.g. <code>notebooks/acme_corp/</code> for one client, and <code>notebooks/nova_solutions/</code> - for another.</p>"},{"location":"docs/teamwork/#training-a-model-or-building-an-ai-agent","title":"Training a Model or Building an AI Agent","text":"<p>If you're developing an AI agent or training a model, start in the <code>app/ai/</code> folder.</p>"},{"location":"docs/teamwork/#automating-business-processes-and-workflows","title":"Automating Business Processes and Workflows","text":"<p>To automate processes or create workflows, use the <code>app/workflows/</code> folder.</p>"},{"location":"docs/teamwork/#scientific-method-workflows-and-experiments","title":"Scientific Method, Workflows and Experiments","text":"<p>If you are a Master's or PhD student, data scientist, business analyst or a product manager designing experiments (e.g., A/B testing or hypothesis testing), use the <code>app/workflows/experiments/</code> subfolder.</p>"},{"location":"docs/teamwork/#extending-arkalos-and-writing-core-helpers-and-modules","title":"Extending Arkalos and Writing Core Helpers and Modules","text":"<p>To modify Arkalos core functions like <code>config()</code>, create implementations in <code>app/core/</code>.</p> <p>For general utility functions, such as custom string handling, place them in <code>app/utils/</code>.</p>"},{"location":"docs/teamwork/#robotics-hardware-avs-and-more","title":"Robotics, Hardware, AVs, and More","text":"<p>If working with robotics or hardware, start in the <code>app/hardware/</code> folder.</p>"},{"location":"docs/teamwork/#what-next","title":"What Next","text":"<p>Now that we know about the app code, modules and working as a team, let's continue to Workflows.</p>"},{"location":"docs/utils/","title":"Utils","text":"<p>Utils are utility or helper functions that simplify coding tasks.</p> <ul> <li>Common utility functions should be placed in the <code>app/utils/</code> folder.</li> <li>Core functions, especially those related to extending the Arkalos framework, should go into the <code>app/core/</code> folder. For example, you can override the default <code>config()</code> function behavior by implementing your own version.</li> </ul>"},{"location":"docs/utils/#available-utils","title":"Available Utils","text":"<p>All utility functions can be imported directly from Arkalos:</p> <pre><code>from arkalos import config, env, dd, var_dump, base_path, get_data_schema\n</code></pre>"},{"location":"docs/utils/#utility-functions","title":"Utility Functions","text":"<ul> <li><code>config('config_file.key')</code> - Retrieves a configuration value.</li> <li><code>env('ENV_KEY')</code> - Fetches an environment variable.</li> <li><code>var_dump(variable)</code> - Displays the contents of a variable for debugging.</li> <li><code>dd(variable)</code> - Dumps a variable and stops execution.</li> <li><code>base_path()</code> - Returns the string of the current base path to the project root. Optionally, can accept an argument.</li> <li><code>get_data_schema(data) -&gt; Polars Schema</code> - Infers data structure from the first rows of the data and returns polars.Schema object.</li> </ul>"},{"location":"docs/utils/#dd-function","title":"<code>dd()</code> Function","text":"<p>The <code>dd()</code> function (short for \"dump and die\") calls <code>var_dump()</code>, but also halts script execution. It is useful for debugging and testing.</p>"},{"location":"docs/utils/#functional-programming-fp-utils","title":"Functional Programming (FP) Utils","text":"<p>Also can be directly imported from the Arkalos:</p> <pre><code>from arkalos import partial, compose, pipe\n</code></pre> <ul> <li><code>partial(function, {args})</code> - Partial Application of a function where a new function is created and certain arguments are fixed. Great for composition or passing functions or classes as arguments into other functions while setting arguments to specific values. (it is a function from <code>functools</code> module)</li> <li><code>compose(function1, function2, ...)</code> - Applies functions right to left.</li> <li><code>pipe(function1, function2,  ...)</code> - Applies functions left to right.</li> </ul>"},{"location":"docs/utils/#debugging-and-logs","title":"Debugging and Logs","text":"<p>Next, explore more debugging and logging tools in the Logs &amp; Debugging section.</p>"},{"location":"docs/web-crawler/","title":"Python Web Extractor, Scraper &amp; Crawler","text":"<p>Before you start, make sure the browser is configured properly.</p> <p>Arkalos includes a powerful built-in WebExtractor tool that allows you to automate the process of gathering data from websites, whether it's downloading full articles, scraping specific information, or crawling multiple pages linked from a start page.</p> <ul> <li>Crawling means starting from a base URL and automatically following internal links to extract data from every page it finds.</li> <li>Scraping means extracting specific data (like a title or price) from a specific page or part of a page.</li> </ul>"},{"location":"docs/web-crawler/#crawling-a-website-saving-web-pages-in-markdown","title":"\ud83d\udd78\ufe0f Crawling a Website: Saving Web Pages in Markdown","text":"<p>Want to download a website\u2019s content for offline reading or AI training? Here's how to crawl the Arkalos documentation and save each page in Markdown format:</p> notebooks/web_extractor.ipynb<pre><code>from arkalos.data.extractors import WebExtractor\n\narkalos = WebExtractor('https://arkalos.com', True, 'article')\narkalos.crawl()\n</code></pre> <p>This creates a folder at <code>data/drive/crawl/arkalos.com/</code> containing one Markdown file per page.</p> <p>WebExtractor parameters:</p> <ol> <li>Base URL \u2013 Starting page.</li> <li>Trailing slash flag \u2013 Set to <code>True</code> if URLs on the site end with a slash (e.g. <code>/docs/</code>).</li> <li>CSS selector for content \u2013 For example <code>main</code>, or a specific <code>.class</code> or <code>#id</code> where the content is located.</li> </ol> <p>Note</p> <p>Arkalos waits for the page and main content area to fully load before scraping.</p> <p>Calling <code>crawl()</code> starts from the base page, discovers internal links, and saves every visited page as Markdown.</p>"},{"location":"docs/web-crawler/#scraping-specific-pages-only","title":"\ud83c\udfaf Scraping Specific Pages Only","text":"<p>You don\u2019t always need the whole website. If you want to scrape specific pages, use:</p> notebooks/web_extractor.ipynb<pre><code>await arkalos.crawlSpecificPages(['docs/installation'])\n</code></pre> <p>Pass a list of relative URLs. Arkalos will visit each and extract the content using the same content selector.</p>"},{"location":"docs/web-crawler/#extracting-specific-details-from-pages","title":"\ud83d\udd0d Extracting Specific Details From Pages","text":"<p>Want to extract things like titles, prices, tags, or ratings from multiple articles on a page? You can create your own structured extractor.</p>"},{"location":"docs/web-crawler/#step-1-define-what-data-to-extract","title":"Step 1: Define what data to extract","text":"<p>Here\u2019s an example website that has this HTML:</p> <pre><code>&lt;article data-id=\"6IF3WGP8V\"&gt;\n  &lt;a href=\"...\"&gt;Title of the article&lt;/a&gt;\n  &lt;div data-item=\"description\"&gt;Article text&lt;/div&gt;\n  &lt;div class=\"rating\"&gt;\n    &lt;img ...&gt;\n    5\n  &lt;/div&gt;\n  &lt;div class=\"tags\"&gt;\n    &lt;span data-item=\"tag\"&gt;Category A&lt;/span&gt;\n    &lt;span data-item=\"tag\"&gt;Category B&lt;/span&gt;\n  &lt;/div&gt;\n&lt;/article&gt;\n</code></pre>"},{"location":"docs/web-crawler/#step-2-create-a-webdetails-class","title":"Step 2: Create a <code>WebDetails</code> class","text":"app/data/extractors/my_website_web_extractor.py<pre><code>from arkalos.data.extractors import WebExtractor, WebDetails, _\nfrom dataclasses import dataclass\nimport polars as pl\n\n@dataclass\nclass ArticleDetails(WebDetails):\n    CONTAINER = 'article[data-id]'\n\n    id: _[str, None, 'data-id']           # Attribute from container\n    url: _[str, 'a', 'href']              # Link\n    title: _[str, 'a']                    # Text from &lt;a&gt;\n    description: _[str, '[data-item=\"description\"]']\n    tags: _[list[str], '[data-item=\"tag\"]']\n    rating: _[int, '.rating', 1]          # Second child (after image)\n</code></pre> <p>The <code>_</code> is a special alias for <code>Annotated</code> to provide typing and selector info in one line.</p>"},{"location":"docs/web-crawler/#step-3-create-your-custom-extractor","title":"Step 3: Create your custom extractor","text":"app/data/extractors/my_website_web_extractor.py<pre><code>class MyWebsiteWebExtractor(WebExtractor):\n    BASE_URL = 'https://mywebsite.com'\n    PAGE_CONTENT_SELECTOR = 'main'\n    SCROLL = True\n    DETAILS = ArticleDetails\n\n    async def crawlTechArticles(self):\n        return await self.crawlSpecificDetails(['/category/tech'])\n</code></pre>"},{"location":"docs/web-crawler/#step-4-run-your-crawler","title":"Step 4: Run your crawler","text":"notebooks/my_web_crawler.ipynb<pre><code>from app.data.extractors.my_website_web_extractor import MyWebsiteWebExtractor\n\nmywebsite = MyWebsiteWebExtractor()\ndata = await mywebsite.crawlTechArticles()\n\ndf = pl.DataFrame(data)\ndf\n</code></pre> <p>You can view the results directly in VS Code using the Data Wrangler extension.</p>"},{"location":"docs/web-crawler/#webdetails-and-annotations","title":"\ud83e\udde9 WebDetails and Annotations","text":"<p>To extract structured data from pages, you define a subclass of <code>WebDetails</code> and annotate each property using a custom annotation format. These annotations tell the scraper what to extract and how.</p> <p>The annotation format is:</p> <pre><code>_[data_type, 'CSS selector' | None, optional_extraction_instruction]\n</code></pre> <ul> <li> <p><code>data_type</code>: The expected Python type of the result. This can be:</p> <ul> <li><code>str</code>, <code>int</code>, <code>float</code></li> <li><code>list[str]</code> \u2014 to extract multiple values as a list using <code>querySelectorAll()</code></li> </ul> </li> <li> <p><code>'CSS selector'</code>: A standard CSS selector string for locating the desired element inside the container. If set to <code>None</code>, the container itself will be used.</p> </li> <li> <p><code>optional_extraction_instruction</code>: Tells how to extract the data. It could be:</p> <ul> <li>An attribute name (e.g. <code>'href'</code>)</li> <li>A <code>slice</code>, like <code>1:</code> or <code>:3</code></li> <li>A regular expression string with one capture group</li> <li>An integer \u2014 to get a specific child node (e.g. the second text node)</li> </ul> </li> </ul> <p>Default Behavior:</p> <p>If you only provide the data type and a CSS selector \u2014 without any extras \u2014 the text content of the element is extracted using <code>.textContent</code>.</p> <p>If the CSS selector doesn't match anything inside the container, the default value for the data type is returned (<code>\"\"</code>, <code>0</code>, etc.).</p> <p>Supported Extraction Instructions (the 3rd argument)</p> <ol> <li> <p>Attribute Name <pre><code>url: _[str, 'a', 'href']\n</code></pre>    Extracts the value of the <code>href</code> attribute from the <code>&lt;a&gt;</code> element.</p> </li> <li> <p>Slice <pre><code>price: _[int, '.price', '1:']  # Skips the currency symbol\n</code></pre>    If <code>.price</code> contains text like <code>\"$99\"</code>, the slice will extract <code>\"99\"</code> and convert it to <code>int</code>.</p> </li> <li> <p>Regular Expression <pre><code>sku: _[str, '.sku', r'ID-(\\w{8})']\n</code></pre>    Extracts matched group from a string like <code>\"Product ID-ABC12345\"</code>.</p> </li> <li> <p>Child Node Index <pre><code>rating: _[int, '.rating', 1]\n</code></pre>    Useful when the target number is inside a sibling text node, and you want to skip over images or other tags.</p> </li> </ol> <p>Lists with querySelectorAll()</p> <p>When the type is <code>list[str]</code>, <code>querySelectorAll()</code> is used instead of <code>querySelector()</code>, and all matched elements\u2019 text contents are extracted into a list:</p> <pre><code>tags: _[list[str], '[data-item=\"tag\"]']\n# \u27f6 ['Category A', 'Category B']\n</code></pre> <p>If You Want to Extract from the Container Itself</p> <p>Set the selector to <code>None</code> and use an attribute name or other instruction:</p> <pre><code>id: _[str, None, 'data-id']\n</code></pre>"},{"location":"docs/web-crawler/#webextractor-constants","title":"\ud83e\uddf1 WebExtractor Constants","text":"<p>Your custom WebExtractor can set these config values:</p> <p>Required:</p> <ul> <li><code>BASE_URL</code>: Starting point for crawling</li> <li><code>PAGE_CONTENT_SELECTOR</code>: The main content selector</li> </ul> <p>Optional:</p> <ul> <li><code>BROWSER_TYPE</code>: Choose browser type (default is <code>EDGE_HEADLESS</code>)</li> <li><code>TRAIL_SLASH</code>: Add a trailing slash to URLs (default <code>False</code>)</li> <li><code>WAIT_FOR_SELECTOR</code>: Wait for this selector to appear before scraping</li> <li><code>CLICK_TEXT</code>: Auto-click this button (e.g. cookie popup) before scraping</li> <li><code>SCROLL</code>: Scroll the page to load dynamic content (default <code>False</code>)</li> </ul> <p>For structured details:</p> <ul> <li><code>DETAILS</code>: Your custom <code>WebDetails</code> class; or</li> <li><code>JSON_DETAILS</code>: or JS code to extract data from JSON blobs on the page</li> </ul>"},{"location":"docs/web-crawler/#scraping-json-data-from-web-pages","title":"\ud83d\udce6 Scraping JSON Data From Web Pages","text":"<p>Some websites store content as embedded JSON inside <code>&lt;script&gt;</code> tags.</p> <p>You can extract it using JavaScript instead of HTML selectors:</p> app/data/extractors/my_website_web_extractor.py<pre><code>class MyWebsiteWebExtractor(WebExtractor):\n    BASE_URL = 'https://mywebsite.com'\n    PAGE_CONTENT_SELECTOR = 'main'\n    JSON_DETAILS = 'JSON.stringify(JSON.parse(document.querySelector(\"script#__DATA__\").textContent).props.articles)'\n\n    async def crawlTechArticles(self):\n        return await self.crawlSpecificDetailsJSON(['/category/tech'])\n</code></pre> <p>Use <code>crawlSpecificDetailsJSON()</code> instead of <code>crawlSpecificDetails()</code> when using JSON extraction.</p>"},{"location":"docs/web-crawler/#get-raw-html-or-a-parsed-html-document","title":"\ud83e\uddfe Get Raw HTML or a Parsed HTML Document","text":"<p>Arkalos can fetch the raw HTML or a parsed document using <code>HTMLDocumentParser</code>.</p> notebooks/crawl.ipynb<pre><code>html = await extractor.getPageHTML(url)\ndoc = await extractor.getPageHTMLDoc(url)\n</code></pre> <p>The <code>doc</code> object has many useful properties:</p> <pre><code>doc.url\ndoc.baseURL\ndoc.domain\ndoc.path\ndoc.charset\ndoc.title\ndoc.meta\ndoc.metaProps\ndoc.links\ndoc.pageLinks\ndoc.internalPageLinks\ndoc.externalPageLinks\ndoc.cleanHTML\ndoc.contentHTML\ndoc.markdown\n</code></pre> <p>You can import <code>HTMLDocumentParser</code> from:</p> <pre><code>from arkalos.utils.html_utils import HTMLDocumentParser\n</code></pre> <p>It uses BeautifulSoup4 (with lxml) and markdownify for conversion to clean Markdown.</p>"},{"location":"docs/workflows/","title":"Workflows","text":"<p>Workflows are structured sequences of steps or processes that automate tasks. They are something between a script and a package.</p> <p>Often, when you start working with data pipelines or automation, you begin by writing scripts and notebooks. However, you may find yourself copying and adapting code for different use cases repeatedly. Workflows help by organizing these repetitive tasks into reusable components.</p> <p>A workflow acts as a controller that brings together multiple modules and data, executing them in a specific order.</p>"},{"location":"docs/workflows/#creating-a-workflow","title":"Creating a Workflow","text":"<p>To create a new workflow, add a new file and class inside the <code>app/workflows/...</code> directory. Implement the <code>Workflow</code> contract (interface), which requires a <code>run()</code> method.</p> <p>Let's say we need a simple workflow with two steps:</p> app/workflows/processes/my_workflow.py<pre><code>from arkalos.workflows.workflow import Workflow\n\nclass MyWorkflow(Workflow):\n\n    def step1(self):\n        print(\"Running step 1 of My Process...\")\n\n    def step2(self):\n        print(\"Running step 2 of My Process...\")\n\n    def run(self):\n        self.step1()\n        self.step2()\n</code></pre> <p>Now, this workflow can be reused across different scripts and notebooks:</p> scripts/my_workflow.py<pre><code>from app.workflows.processes.my_workflow import MyWorkflow\n\nwf = MyWorkflow()\nwf.run()\n</code></pre> <p>Run the script using:</p> <pre><code>uv run scripts/my_workflow.py\n</code></pre>"},{"location":"docs/workflows/#etlworkflow","title":"ETLWorkflow","text":"<p>ETL stands for Extract, Transform, and Load \u2014 a common pattern in data pipelines. Arkalos includes an <code>ETLWorkflow</code> that simplifies data extraction and loading into a configured data warehouse.</p> <p>To use it, provide an extractor class as the first argument:</p> scripts/etl/sync_airtable_dwh.py<pre><code>from arkalos.data.extractors.airtable_extractor import AirtableExtractor\nfrom arkalos.workflows.etl_workflow import ETLWorkflow\n\nwf = ETLWorkflow(AirtableExtractor)\nwf.run(drop_tables=True)\n</code></pre> <p>The <code>run()</code> method accepts parameters such as <code>drop_tables=True</code>, which ensures data is refreshed on every run.</p> <p>Note</p> <p>Currently, we recommend dropping tables in your warehouse since Arkalos is in development. This ensures data is always in sync but is not ideal for handling large datasets.</p> <p>Optionally, you can specify a data warehouse class as a second argument:</p> scripts/etl/my_custom_etl.py<pre><code>from arkalos.data.extractors.airtable_extractor import AirtableExtractor\nfrom arkalos.data.warehouse.sqlite.sqlite_warehouse import SQLiteWarehouse\n\nwf = ETLWorkflow(\n    AirtableExtractor,\n    SQLiteWarehouse\n)\nwf.run(drop_tables=True)\n</code></pre> <p>You can also create your own extractor and warehouse implementation. See the Working with Data guide for more details.</p>"},{"location":"docs/workflows/#whats-next","title":"What\u2019s Next?","text":"<p>Now that you understand workflows, continue to the Utils section to learn about utility functions and helpers.</p>"}]}